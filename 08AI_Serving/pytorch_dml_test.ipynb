{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c490c5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DirectML을 통한 GPU 사용 가능: privateuseone:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch_directml\n",
    "\n",
    "# DirectML 디바이스 생성\n",
    "device = torch_directml.device()\n",
    "\n",
    "# 사용 가능한 DirectML 디바이스 출력\n",
    "if device:\n",
    "    print(f\"DirectML을 통한 GPU 사용 가능: {device}\")\n",
    "else:\n",
    "    print(\"DirectML을 통한 GPU가 사용 불가능합니다.\")\n",
    "\n",
    "dml = torch_directml.device()\n",
    "tensor1 = torch.tensor([1]).to(dml) # Note that dml is a variable, not a string!\n",
    "tensor2 = torch.tensor([2]).to(dml)\n",
    "dml_algebra = tensor1 + tensor2\n",
    "dml_algebra.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0192d20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from transformers[torch]) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers[torch])\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from transformers[torch]) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch])\n",
      "  Downloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers[torch])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers[torch])\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers[torch])\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers[torch])\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from transformers[torch]) (2.4.1)\n",
      "Requirement already satisfied: psutil in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers[torch]) (6.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from torch->transformers[torch]) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.6.68)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers[torch])\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers[torch])\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers[torch])\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Downloading huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
      "Downloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.8/792.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, accelerate, transformers\n",
      "Successfully installed accelerate-0.34.2 certifi-2024.8.30 charset-normalizer-3.3.2 huggingface-hub-0.25.0 regex-2024.9.11 requests-2.32.3 safetensors-0.4.5 tokenizers-0.19.1 tqdm-4.66.5 transformers-4.44.2 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install 'transformers[torch]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774abe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1fb040c",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/pipeline_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f74999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\")\n",
    "# 음성인식 모델을 다운받아서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d5e9c0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ffmpeg was not found but is required to load audio files from filename",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/audio_utils.py:34\u001b[0m, in \u001b[0;36mffmpeg_read\u001b[0;34m(bpayload, sampling_rate)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mffmpeg_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ffmpeg_process:\n\u001b[1;32m     35\u001b[0m         output_stream \u001b[38;5;241m=\u001b[39m ffmpeg_process\u001b[38;5;241m.\u001b[39mcommunicate(bpayload)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/subprocess.py:1955\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtranscriber\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py:284\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    223\u001b[0m     inputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    225\u001b[0m ):\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    documentation for more information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/base.py:1249\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:33\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:186\u001b[0m, in \u001b[0;36mPipelineChunkIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# Try to return next item\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubiterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# When a preprocess iterator ends, we can start lookig at the next item\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# ChunkIterator will keep feeding until ALL elements of iterator\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Another way to look at it, is we're basically flattening lists of lists\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# into a single list, but with generators\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py:361\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.preprocess\u001b[0;34m(self, inputs, chunk_length_s, stride_length_s)\u001b[0m\n\u001b[1;32m    358\u001b[0m             inputs \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m--> 361\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mffmpeg_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    364\u001b[0m extra \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/pipelines/audio_utils.py:37\u001b[0m, in \u001b[0;36mffmpeg_read\u001b[0;34m(bpayload, sampling_rate)\u001b[0m\n\u001b[1;32m     35\u001b[0m         output_stream \u001b[38;5;241m=\u001b[39m ffmpeg_process\u001b[38;5;241m.\u001b[39mcommunicate(bpayload)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffmpeg was not found but is required to load audio files from filename\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n\u001b[1;32m     38\u001b[0m out_bytes \u001b[38;5;241m=\u001b[39m output_stream[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     39\u001b[0m audio \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(out_bytes, np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mValueError\u001b[0m: ffmpeg was not found but is required to load audio files from filename"
     ]
    }
   ],
   "source": [
    "transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5f2ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e011aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4335, 'label': 'lynx, catamount'},\n",
       " {'score': 0.0348,\n",
       "  'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'},\n",
       " {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'},\n",
       " {'score': 0.0239, 'label': 'Egyptian cat'},\n",
       " {'score': 0.0229, 'label': 'tiger cat'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "vision_classifier = pipeline(model=\"google/vit-base-patch16-224\")\n",
    "preds = vision_classifier(\n",
    "    images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8e36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b57bc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5036353468894958,\n",
       "  0.478799968957901,\n",
       "  0.012600144371390343,\n",
       "  0.0026557829696685076,\n",
       "  0.0023087612353265285]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# This model is a `zero-shot-classification` model.\n",
    "# It will classify text, except you are free to choose any label you might imagine\n",
    "classifier = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "classifier(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f417e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio==3.40.0\n",
      "  Downloading gradio-3.40.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (23.2.1)\n",
      "Collecting aiohttp~=3.0 (from gradio==3.40.0)\n",
      "  Downloading aiohttp-3.10.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio==3.40.0)\n",
      "  Downloading altair-5.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: fastapi in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (0.115.0)\n",
      "Requirement already satisfied: ffmpy in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (0.4.0)\n",
      "Requirement already satisfied: gradio-client>=0.4.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (1.3.0)\n",
      "Requirement already satisfied: httpx in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (0.25.0)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (6.4.5)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (3.1.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.0.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0) (3.0.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (3.9.2)\n",
      "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.40.0)\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy~=1.0 (from gradio==3.40.0)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (3.10.7)\n",
      "Requirement already satisfied: packaging in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (2.2.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (10.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (2.9.2)\n",
      "Requirement already satisfied: pydub in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (0.0.10)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (6.0.2)\n",
      "Requirement already satisfied: requests~=2.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (2.32.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio==3.40.0) (0.30.6)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio==3.40.0)\n",
      "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp~=3.0->gradio==3.40.0)\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp~=3.0->gradio==3.40.0)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from aiohttp~=3.0->gradio==3.40.0) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp~=3.0->gradio==3.40.0)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp~=3.0->gradio==3.40.0)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp~=3.0->gradio==3.40.0)\n",
      "  Downloading yarl-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.40.0) (4.23.0)\n",
      "Collecting narwhals>=1.5.2 (from altair<6.0,>=4.2.0->gradio==3.40.0)\n",
      "  Downloading narwhals-1.8.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: fsspec in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from gradio-client>=0.4.0->gradio==3.40.0) (2024.9.0)\n",
      "Requirement already satisfied: anyio in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from httpx->gradio==3.40.0) (4.6.0)\n",
      "Requirement already satisfied: certifi in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from httpx->gradio==3.40.0) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from httpx->gradio==3.40.0) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from httpx->gradio==3.40.0) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from httpx->gradio==3.40.0) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from httpcore==1.*->httpx->gradio==3.40.0) (0.14.0)\n",
      "Requirement already satisfied: filelock in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio==3.40.0) (3.16.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio==3.40.0) (4.66.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0) (0.1.2)\n",
      "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio==3.40.0)\n",
      "  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.40.0) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.40.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.40.0) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.40.0) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.40.0) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.40.0) (2.9.0.post0)\n",
      "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.40.0)\n",
      "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.40.0)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==3.40.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==3.40.0) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.40.0) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from requests~=2.0->gradio==3.40.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from requests~=2.0->gradio==3.40.0) (2.2.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio==3.40.0) (8.1.7)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from fastapi->gradio==3.40.0) (0.38.6)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.40.0) (0.20.0)\n",
      "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.40.0)\n",
      "  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/miniforge3/envs/torch/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.40.0) (1.16.0)\n",
      "Downloading gradio-3.40.0-py3-none-any.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.1/658.1 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading narwhals-1.8.2-py3-none-any.whl (167 kB)\n",
      "Downloading yarl-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (487 kB)\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: websockets, uc-micro-py, numpy, narwhals, multidict, markdown-it-py, frozenlist, aiohappyeyeballs, yarl, mdit-py-plugins, linkify-it-py, aiosignal, aiohttp, altair, gradio\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 12.0\n",
      "    Uninstalling websockets-12.0:\n",
      "      Successfully uninstalled websockets-12.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "  Attempting uninstall: markdown-it-py\n",
      "    Found existing installation: markdown-it-py 3.0.0\n",
      "    Uninstalling markdown-it-py-3.0.0:\n",
      "      Successfully uninstalled markdown-it-py-3.0.0\n",
      "  Attempting uninstall: gradio\n",
      "    Found existing installation: gradio 4.44.0\n",
      "    Uninstalling gradio-4.44.0:\n",
      "      Successfully uninstalled gradio-4.44.0\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 altair-5.4.1 frozenlist-1.4.1 gradio-3.40.0 linkify-it-py-2.0.3 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 multidict-6.1.0 narwhals-1.8.2 numpy-1.26.4 uc-micro-py-1.0.3 websockets-11.0.3 yarl-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio==3.40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f7ceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "/tmp/ipykernel_9783/2233220952.py:6: GradioUnusedKwargWarning: You have unused kwarg parameters in Label, please remove them: {'type': 'confidences'}\n",
      "  app = gr.Interface.from_pipeline(pipe)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://434416fc966418d192.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "pipe = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
    "\n",
    "app = gr.Interface.from_pipeline(pipe)\n",
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a654a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30dc57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df35f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808e52e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf2b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
