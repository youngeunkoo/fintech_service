{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e0e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 밑에 실행하면서 뜨는 빨간 경고 팝업 뜨지 않게 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731ab3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca81c049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/wine.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c7104",
   "metadata": {},
   "source": [
    "1) Alcohol\n",
    "2) Malic acid\n",
    "3) Ash\n",
    "4) Alcalinity of ash\n",
    "5) Magnesium\n",
    "6) Total phenols\n",
    "7) Flavanoids\n",
    "8) Nonflavanoid phenols\n",
    "9) Proanthocyanins\n",
    "10) Color intensity\n",
    "11) Hue\n",
    "12) OD280/OD315 of diluted wines\n",
    "13) Proline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8891a0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa4f10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b90c065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data.iloc[:,0:4])\n",
    "\n",
    "# 이상값이 상당히 많음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4377e582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12\n",
       "0    4898\n",
       "1    1599\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[12].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3b0570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(12, axis=1)\n",
    "y = data[12]\n",
    "\n",
    "# 칼럼 12 가 target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af56a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링하기 \n",
    "\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "323a9541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30769231,  2.41176471, -2.21428571, ...,  0.29411765,\n",
       "        -0.5       , -1.        ],\n",
       "       [ 0.61538462,  3.47058824, -2.21428571, ...,  1.        ,\n",
       "        -0.27777778, -1.        ],\n",
       "       [ 0.61538462,  2.76470588, -1.92857143, ...,  0.82352941,\n",
       "        -0.27777778, -1.        ],\n",
       "       ...,\n",
       "       [-0.38461538, -0.29411765, -0.85714286, ..., -0.29411765,\n",
       "        -0.5       ,  0.        ],\n",
       "       [-1.15384615,  0.        , -0.07142857, ..., -0.76470588,\n",
       "         1.38888889,  1.        ],\n",
       "       [-0.76923077, -0.47058824,  0.5       , ..., -1.11764706,\n",
       "         0.83333333,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RobustScaler()\n",
    "X_scaled = rs.fit_transform(X)\n",
    "X_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d52916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "6492    0\n",
       "6493    0\n",
       "6494    0\n",
       "6495    0\n",
       "6496    0\n",
       "Name: 12, Length: 6497, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cc620d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 홀드아웃으로 나눠서 분석하기 \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d9f0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 6000개이니 valid 로 하기 \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.4, random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e6942",
   "metadata": {},
   "source": [
    "# Sequential 로 해보기 (함수형/클래스형 아무거나 상관없음) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce8c6249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:17:31.986088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 09:17:34.572602: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2024-09-11 09:17:34.572753: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2024-09-11 09:17:34.577005: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2024-09-11 09:17:34.823003: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "# 1) Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e004aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3898, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd48deb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8557c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                416       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,089\n",
      "Trainable params: 1,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:17:35.227765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 09:17:35.229734: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (AMD Radeon(TM) Graphics)\n",
      "2024-09-11 09:17:35.312807: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:17:35.312853: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2024-09-11 09:17:35.312874: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))   # 입력층\n",
    "model.add(Dense(16, activation='relu'))                 # 은닉층 1\n",
    "model.add(Dense(8, activation='relu'))                  # 은닉층 2\n",
    "model.add(Dense(1, activation='sigmoid'))               # 출력층, y가 이진법 (0,1) 이기 때문에 sigmoid\n",
    "model.summary()\n",
    "\n",
    "# y가 이진법 (0,1) 이기 때문에 sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b50d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.7461 - accuracy: 0.3674"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:17:36.027006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:17:36.097811: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:17:36.097869: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 34ms/step - loss: 0.7399 - accuracy: 0.3807 - val_loss: 0.6716 - val_accuracy: 0.5158\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6356 - accuracy: 0.6473 - val_loss: 0.5859 - val_accuracy: 0.7837\n",
      "Epoch 3/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.5905 - accuracy: 0.8180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:17:36.356417: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:17:36.381784: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:17:36.381843: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5607 - accuracy: 0.8633 - val_loss: 0.5227 - val_accuracy: 0.9315\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5026 - accuracy: 0.9433 - val_loss: 0.4694 - val_accuracy: 0.9561\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4501 - accuracy: 0.9618 - val_loss: 0.4184 - val_accuracy: 0.9684\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3987 - accuracy: 0.9684 - val_loss: 0.3675 - val_accuracy: 0.9715\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3474 - accuracy: 0.9736 - val_loss: 0.3165 - val_accuracy: 0.9808\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2968 - accuracy: 0.9764 - val_loss: 0.2673 - val_accuracy: 0.9838\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2490 - accuracy: 0.9805 - val_loss: 0.2220 - val_accuracy: 0.9846\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2061 - accuracy: 0.9841 - val_loss: 0.1825 - val_accuracy: 0.9854\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1697 - accuracy: 0.9867 - val_loss: 0.1498 - val_accuracy: 0.9892\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1399 - accuracy: 0.9877 - val_loss: 0.1236 - val_accuracy: 0.9908\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1168 - accuracy: 0.9885 - val_loss: 0.1031 - val_accuracy: 0.9923\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0990 - accuracy: 0.9897 - val_loss: 0.0872 - val_accuracy: 0.9923\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0853 - accuracy: 0.9910 - val_loss: 0.0749 - val_accuracy: 0.9923\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0748 - accuracy: 0.9915 - val_loss: 0.0653 - val_accuracy: 0.9923\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0666 - accuracy: 0.9920 - val_loss: 0.0579 - val_accuracy: 0.9923\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0601 - accuracy: 0.9918 - val_loss: 0.0519 - val_accuracy: 0.9938\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0551 - accuracy: 0.9918 - val_loss: 0.0470 - val_accuracy: 0.9938\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0511 - accuracy: 0.9926 - val_loss: 0.0429 - val_accuracy: 0.9938\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0475 - accuracy: 0.9928 - val_loss: 0.0395 - val_accuracy: 0.9931\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0447 - accuracy: 0.9931 - val_loss: 0.0368 - val_accuracy: 0.9938\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0423 - accuracy: 0.9928 - val_loss: 0.0342 - val_accuracy: 0.9938\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0402 - accuracy: 0.9938 - val_loss: 0.0321 - val_accuracy: 0.9954\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0384 - accuracy: 0.9938 - val_loss: 0.0303 - val_accuracy: 0.9954\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0368 - accuracy: 0.9938 - val_loss: 0.0287 - val_accuracy: 0.9962\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0354 - accuracy: 0.9949 - val_loss: 0.0273 - val_accuracy: 0.9962\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0341 - accuracy: 0.9946 - val_loss: 0.0260 - val_accuracy: 0.9962\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0330 - accuracy: 0.9949 - val_loss: 0.0249 - val_accuracy: 0.9962\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0320 - accuracy: 0.9946 - val_loss: 0.0239 - val_accuracy: 0.9962\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0311 - accuracy: 0.9946 - val_loss: 0.0230 - val_accuracy: 0.9962\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9951 - val_loss: 0.0222 - val_accuracy: 0.9962\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0294 - accuracy: 0.9951 - val_loss: 0.0215 - val_accuracy: 0.9962\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0288 - accuracy: 0.9951 - val_loss: 0.0209 - val_accuracy: 0.9962\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0281 - accuracy: 0.9954 - val_loss: 0.0202 - val_accuracy: 0.9962\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9956 - val_loss: 0.0196 - val_accuracy: 0.9962\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0269 - accuracy: 0.9956 - val_loss: 0.0191 - val_accuracy: 0.9962\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0263 - accuracy: 0.9956 - val_loss: 0.0188 - val_accuracy: 0.9962\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0259 - accuracy: 0.9956 - val_loss: 0.0183 - val_accuracy: 0.9962\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0254 - accuracy: 0.9956 - val_loss: 0.0178 - val_accuracy: 0.9962\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0250 - accuracy: 0.9956 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0246 - accuracy: 0.9959 - val_loss: 0.0170 - val_accuracy: 0.9962\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0242 - accuracy: 0.9962 - val_loss: 0.0167 - val_accuracy: 0.9962\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0238 - accuracy: 0.9962 - val_loss: 0.0165 - val_accuracy: 0.9962\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0235 - accuracy: 0.9962 - val_loss: 0.0163 - val_accuracy: 0.9962\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9962 - val_loss: 0.0160 - val_accuracy: 0.9962\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9962 - val_loss: 0.0156 - val_accuracy: 0.9969\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0225 - accuracy: 0.9962 - val_loss: 0.0154 - val_accuracy: 0.9969\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 0.0153 - val_accuracy: 0.9962\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 0.0151 - val_accuracy: 0.9962\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0217 - accuracy: 0.9969 - val_loss: 0.0148 - val_accuracy: 0.9962\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0215 - accuracy: 0.9967 - val_loss: 0.0146 - val_accuracy: 0.9962\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9969 - val_loss: 0.0146 - val_accuracy: 0.9962\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 0.9969 - val_loss: 0.0144 - val_accuracy: 0.9962\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 0.0141 - val_accuracy: 0.9969\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0205 - accuracy: 0.9969 - val_loss: 0.0140 - val_accuracy: 0.9969\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 0.0138 - val_accuracy: 0.9969\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0201 - accuracy: 0.9969 - val_loss: 0.0137 - val_accuracy: 0.9969\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0199 - accuracy: 0.9969 - val_loss: 0.0137 - val_accuracy: 0.9969\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0197 - accuracy: 0.9969 - val_loss: 0.0135 - val_accuracy: 0.9969\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0195 - accuracy: 0.9969 - val_loss: 0.0133 - val_accuracy: 0.9969\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0193 - accuracy: 0.9969 - val_loss: 0.0133 - val_accuracy: 0.9969\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0191 - accuracy: 0.9969 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9969 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9969 - val_loss: 0.0129 - val_accuracy: 0.9969\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0129 - val_accuracy: 0.9969\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0184 - accuracy: 0.9969 - val_loss: 0.0127 - val_accuracy: 0.9969\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9969 - val_loss: 0.0126 - val_accuracy: 0.9969\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0125 - val_accuracy: 0.9969\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.0125 - val_accuracy: 0.9969\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.0124 - val_accuracy: 0.9969\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.0122 - val_accuracy: 0.9969\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.0122 - val_accuracy: 0.9969\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.0121 - val_accuracy: 0.9969\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0172 - accuracy: 0.9969 - val_loss: 0.0120 - val_accuracy: 0.9969\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 0.0119 - val_accuracy: 0.9969\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0169 - accuracy: 0.9969 - val_loss: 0.0118 - val_accuracy: 0.9969\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0168 - accuracy: 0.9969 - val_loss: 0.0118 - val_accuracy: 0.9969\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0117 - val_accuracy: 0.9969\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.0117 - val_accuracy: 0.9969\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0117 - val_accuracy: 0.9969\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 0.0114 - val_accuracy: 0.9969\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 0.9972 - val_loss: 0.0114 - val_accuracy: 0.9969\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.9972 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0158 - accuracy: 0.9972 - val_loss: 0.0112 - val_accuracy: 0.9969\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0157 - accuracy: 0.9972 - val_loss: 0.0112 - val_accuracy: 0.9969\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0156 - accuracy: 0.9972 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 0.0113 - val_accuracy: 0.9969\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0154 - accuracy: 0.9972 - val_loss: 0.0112 - val_accuracy: 0.9969\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0152 - accuracy: 0.9972 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.0109 - val_accuracy: 0.9969\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0150 - accuracy: 0.9972 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.0109 - val_accuracy: 0.9969\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0148 - accuracy: 0.9972 - val_loss: 0.0108 - val_accuracy: 0.9962\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0147 - accuracy: 0.9972 - val_loss: 0.0109 - val_accuracy: 0.9969\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0146 - accuracy: 0.9972 - val_loss: 0.0108 - val_accuracy: 0.9962\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.0108 - val_accuracy: 0.9962\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.0108 - val_accuracy: 0.9962\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.0107 - val_accuracy: 0.9962\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs = 100, batch_size = 500, validation_data = (X_valid, y_valid)) \n",
    "\n",
    "\n",
    "# y가 이진법 (0,1) 이기 때문에 sigmoid\n",
    "# 그래서 loss 부분도 binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbeddaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       976\n",
      "           1       0.99      0.98      0.99       324\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:17:47.737413: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:17:47.872005: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:17:47.872067: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-11 09:17:47.888118: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:17:47.888180: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-11 09:17:47.893170: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:17:47.893228: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred = pred[0].apply(lambda x : 1 if x > 0.5 else 0)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bd8b7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c87108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'valid'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d647b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "966da484",
   "metadata": {},
   "source": [
    "# EarlyStopping 으로 학습 조기 중단 및 저장하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56f377",
   "metadata": {},
   "source": [
    "* EarlyStopping : 성능 개선이 멈추면 학습을 조기에 중단하는 콜백 \n",
    "* ModelCheckpoint : 학습 중 가장 성능이 좋은 모델을 자동으로 저장하는 콜백 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f98cfd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b395b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience=30)\n",
    "\n",
    "# patience=30 이 부분의 수치를 바꾸면 새로 실행되고 파일에 저장됨\n",
    "# patience=50 이렇게 바꿈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c89d40",
   "metadata": {},
   "source": [
    "# ModelCheckpoint \n",
    "* 모델을 중간에 저장하는 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee4763dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /model already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./model\"):\n",
    "        os.makedirs(\"./model\")\n",
    "        print(f\"Directory /model created.\")\n",
    "else:\n",
    "        print(f\"Directory /model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83ad4d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./model/{epoch:03d}--{val_loss:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0e6fec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.0143 - accuracy: 0.9972 - val_loss: 0.0108 - val_accuracy: 0.9962\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 0.0107 - val_accuracy: 0.9962\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.0106 - val_accuracy: 0.9962\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.0107 - val_accuracy: 0.9962\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0139 - accuracy: 0.9972 - val_loss: 0.0106 - val_accuracy: 0.9962\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9962\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 0.0106 - val_accuracy: 0.9962\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9962\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.0106 - val_accuracy: 0.9962\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9962\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9962\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.0104 - val_accuracy: 0.9962\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0131 - accuracy: 0.9972 - val_loss: 0.0104 - val_accuracy: 0.9962\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0131 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9962\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 0.0102 - val_accuracy: 0.9962\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.0101 - val_accuracy: 0.9962\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 0.0100 - val_accuracy: 0.9962\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0102 - val_accuracy: 0.9962\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0103 - val_accuracy: 0.9962\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0101 - val_accuracy: 0.9962\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0101 - val_accuracy: 0.9962\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0101 - val_accuracy: 0.9962\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0101 - val_accuracy: 0.9962\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0099 - val_accuracy: 0.9962\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.0099 - val_accuracy: 0.9962\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.0100 - val_accuracy: 0.9962\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0099 - val_accuracy: 0.9962\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0100 - val_accuracy: 0.9962\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.0100 - val_accuracy: 0.9962\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.0097 - val_accuracy: 0.9962\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0096 - val_accuracy: 0.9962\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0096 - val_accuracy: 0.9962\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.0095 - val_accuracy: 0.9962\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.0096 - val_accuracy: 0.9962\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0097 - val_accuracy: 0.9962\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0096 - val_accuracy: 0.9962\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.0093 - val_accuracy: 0.9962\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0094 - val_accuracy: 0.9962\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0095 - val_accuracy: 0.9962\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.0095 - val_accuracy: 0.9962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.0093 - val_accuracy: 0.9962\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.0093 - val_accuracy: 0.9962\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0093 - val_accuracy: 0.9962\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.0094 - val_accuracy: 0.9962\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0094 - val_accuracy: 0.9962\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9969\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0092 - val_accuracy: 0.9969\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0093 - val_accuracy: 0.9969\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.0092 - val_accuracy: 0.9969\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0092 - val_accuracy: 0.9969\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9969\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9969\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0092 - val_accuracy: 0.9969\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.0092 - val_accuracy: 0.9969\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9969\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0089 - val_accuracy: 0.9969\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9969\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9962\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9962\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9962\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0089 - val_accuracy: 0.9969\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9962\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9962\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9962\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9962\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9962\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0089 - val_accuracy: 0.9962\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0089 - val_accuracy: 0.9962\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0090 - val_accuracy: 0.9962\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0091 - val_accuracy: 0.9962\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0090 - val_accuracy: 0.9962\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0091 - val_accuracy: 0.9962\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0093 - val_accuracy: 0.9962\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0090 - val_accuracy: 0.9962\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0091 - val_accuracy: 0.9962\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0093 - val_accuracy: 0.9962\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0094 - val_accuracy: 0.9962\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0095 - val_accuracy: 0.9962\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0093 - val_accuracy: 0.9962\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0092 - val_accuracy: 0.9962\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0096 - val_accuracy: 0.9962\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0096 - val_accuracy: 0.9962\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0095 - val_accuracy: 0.9962\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0094 - val_accuracy: 0.9962\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0097 - val_accuracy: 0.9962\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0097 - val_accuracy: 0.9962\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0094 - val_accuracy: 0.9962\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0095 - val_accuracy: 0.9962\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0097 - val_accuracy: 0.9962\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0098 - val_accuracy: 0.9962\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0095 - val_accuracy: 0.9962\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0097 - val_accuracy: 0.9962\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 1000, batch_size = 500, validation_data = (X_valid, y_valid), \n",
    "                    callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaff01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea08e3aa",
   "metadata": {},
   "source": [
    "# 저장된 베스트 모델을 불러와서 테스트 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49114e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae7203db",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"./model/001--0.0097.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea8028c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       976\n",
      "           1       0.99      0.99      0.99       324\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      0.99      0.99      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:18:03.941462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "best_pred = best_model.predict(X_test)\n",
    "best_pred = pd.DataFrame(best_pred)\n",
    "best_pred = best_pred[0].apply(lambda x:1 if x > 0.5 else 0)\n",
    "print(classification_report(y_test,best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be75ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb61df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f05a061",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a9437f",
   "metadata": {},
   "source": [
    "## 다른 데이터로 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "171e2569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(\"../07deep_learning/data/winequality-white.csv\", sep = \";\")\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3c56500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()\n",
    "\n",
    "# 결측치없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4876122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c36e09d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "976c8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('quality', axis=1).copy()\n",
    "y = wine['quality'].copy()\n",
    "y2 = wine['quality'].copy()\n",
    "\n",
    "# wine['quality'] 가 target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3a5bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링하기 \n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "# 이상치가 많기 때문에 RobustScaler 로 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f577d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2       ,  0.09090909,  0.33333333, ..., -0.94736842,\n",
       "        -0.14285714, -0.84210526],\n",
       "       [-0.5       ,  0.36363636,  0.16666667, ...,  0.63157895,\n",
       "         0.14285714, -0.47368421],\n",
       "       [ 1.3       ,  0.18181818,  0.66666667, ...,  0.42105263,\n",
       "        -0.21428571, -0.15789474],\n",
       "       ...,\n",
       "       [-0.3       , -0.18181818, -1.08333333, ..., -1.        ,\n",
       "        -0.07142857, -0.52631579],\n",
       "       [-1.3       ,  0.27272727, -0.16666667, ...,  0.84210526,\n",
       "        -0.64285714,  1.26315789],\n",
       "       [-0.8       , -0.45454545,  0.5       , ...,  0.42105263,\n",
       "        -1.07142857,  0.73684211]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 =  RobustScaler() # 중앙값과 IQR 을 사용한 스케일링\n",
    "\n",
    "X_scaled = rs2.fit_transform(X)\n",
    "X_scaled\n",
    "\n",
    "# 중앙값을 기준으로 스케일링하고, 사분위 범위를 사용하여 이상치의 영향을 줄인다. \n",
    "# 이상치에 강한 스케일링 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ddb93",
   "metadata": {},
   "source": [
    "* StandardScaler : 데이터가 정규분포를 따르는 경우 가장 적합\n",
    "* MinMaxScaler : 피처 값이 다양한 범위에 분포되어 있고, 이상치가 많으면 적합함\n",
    "* RobustScaler : 이상치가 많은 경우에 유리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec4b6b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6230d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 홀드아웃으로 나눠서 분석하기 \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c74f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 4000개이니 valid 로 하기 \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.4, stratify=y, random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921226b6",
   "metadata": {},
   "source": [
    "# Sequential 로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f32a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bf2c0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d57363d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                768       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,687\n",
      "Trainable params: 7,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))   # 입력층\n",
    "model2.add(Dense(32, activation='relu'))                  # 은닉층 1\n",
    "model2.add(Dense(64, activation='relu'))                  # 은닉층 2\n",
    "model2.add(Dense(32, activation='relu'))                  # 은닉층 3\n",
    "model2.add(Dense(16, activation='relu'))                  # 은닉층 4\n",
    "model2.add(Dense(7, activation='softmax'))                # 출력층, 다중분류\n",
    "# 클래스가 7개이기 때문에 7을 준다.\n",
    "model2.summary()\n",
    "\n",
    "# 다중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484e47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11179d29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.8860 - accuracy: 0.0776"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:18:05.099145: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:18:05.156884: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:18:05.156941: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 59ms/step - loss: 1.8860 - accuracy: 0.0776 - val_loss: 1.8249 - val_accuracy: 0.1755\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.7849 - accuracy: 0.2491"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:18:05.367535: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:18:05.395093: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:18:05.395152: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 30ms/step - loss: 1.7849 - accuracy: 0.2491 - val_loss: 1.7357 - val_accuracy: 0.3704\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.6929 - accuracy: 0.4091 - val_loss: 1.6423 - val_accuracy: 0.4388\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.5923 - accuracy: 0.4483 - val_loss: 1.5370 - val_accuracy: 0.4510\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.4800 - accuracy: 0.4523 - val_loss: 1.4309 - val_accuracy: 0.4480\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.3849 - accuracy: 0.4558 - val_loss: 1.3600 - val_accuracy: 0.4592\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.3236 - accuracy: 0.4816 - val_loss: 1.3225 - val_accuracy: 0.5010\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.2848 - accuracy: 0.5048 - val_loss: 1.2885 - val_accuracy: 0.5010\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.2486 - accuracy: 0.5163 - val_loss: 1.2562 - val_accuracy: 0.5204\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.2147 - accuracy: 0.5235 - val_loss: 1.2242 - val_accuracy: 0.5153\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.1839 - accuracy: 0.5245 - val_loss: 1.1974 - val_accuracy: 0.5286\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.1572 - accuracy: 0.5374 - val_loss: 1.1739 - val_accuracy: 0.5306\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.1355 - accuracy: 0.5361 - val_loss: 1.1546 - val_accuracy: 0.5408\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1180 - accuracy: 0.5408 - val_loss: 1.1393 - val_accuracy: 0.5439\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1023 - accuracy: 0.5596 - val_loss: 1.1266 - val_accuracy: 0.5592\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0877 - accuracy: 0.5589 - val_loss: 1.1136 - val_accuracy: 0.5602\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0770 - accuracy: 0.5599 - val_loss: 1.1054 - val_accuracy: 0.5602\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0673 - accuracy: 0.5596 - val_loss: 1.0983 - val_accuracy: 0.5653\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0596 - accuracy: 0.5708 - val_loss: 1.0949 - val_accuracy: 0.5561\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0537 - accuracy: 0.5650 - val_loss: 1.0883 - val_accuracy: 0.5633\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0476 - accuracy: 0.5735 - val_loss: 1.0836 - val_accuracy: 0.5735\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0394 - accuracy: 0.5762 - val_loss: 1.0797 - val_accuracy: 0.5714\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.0324 - accuracy: 0.5786 - val_loss: 1.0762 - val_accuracy: 0.5735\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0262 - accuracy: 0.5800 - val_loss: 1.0738 - val_accuracy: 0.5724\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0207 - accuracy: 0.5803 - val_loss: 1.0716 - val_accuracy: 0.5735\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0156 - accuracy: 0.5885 - val_loss: 1.0694 - val_accuracy: 0.5694\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0125 - accuracy: 0.5810 - val_loss: 1.0667 - val_accuracy: 0.5694\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0112 - accuracy: 0.5827 - val_loss: 1.0633 - val_accuracy: 0.5714\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0090 - accuracy: 0.5824 - val_loss: 1.0640 - val_accuracy: 0.5673\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0063 - accuracy: 0.5844 - val_loss: 1.0594 - val_accuracy: 0.5714\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9954 - accuracy: 0.5837 - val_loss: 1.0570 - val_accuracy: 0.5745\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9905 - accuracy: 0.5953 - val_loss: 1.0540 - val_accuracy: 0.5684\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9838 - accuracy: 0.5970 - val_loss: 1.0525 - val_accuracy: 0.5704\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9808 - accuracy: 0.5994 - val_loss: 1.0498 - val_accuracy: 0.5755\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9742 - accuracy: 0.5997 - val_loss: 1.0491 - val_accuracy: 0.5622\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9705 - accuracy: 0.5997 - val_loss: 1.0494 - val_accuracy: 0.5714\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9665 - accuracy: 0.6038 - val_loss: 1.0461 - val_accuracy: 0.5582\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9641 - accuracy: 0.5997 - val_loss: 1.0516 - val_accuracy: 0.5663\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9594 - accuracy: 0.6025 - val_loss: 1.0447 - val_accuracy: 0.5653\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9544 - accuracy: 0.6048 - val_loss: 1.0481 - val_accuracy: 0.5694\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9523 - accuracy: 0.6031 - val_loss: 1.0447 - val_accuracy: 0.5673\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9469 - accuracy: 0.6082 - val_loss: 1.0452 - val_accuracy: 0.5612\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9415 - accuracy: 0.6072 - val_loss: 1.0455 - val_accuracy: 0.5643\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9391 - accuracy: 0.6099 - val_loss: 1.0437 - val_accuracy: 0.5663\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9374 - accuracy: 0.6082 - val_loss: 1.0501 - val_accuracy: 0.5551\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9341 - accuracy: 0.6079 - val_loss: 1.0413 - val_accuracy: 0.5582\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9307 - accuracy: 0.6120 - val_loss: 1.0392 - val_accuracy: 0.5724\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9215 - accuracy: 0.6195 - val_loss: 1.0415 - val_accuracy: 0.5673\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9179 - accuracy: 0.6178 - val_loss: 1.0464 - val_accuracy: 0.5571\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9163 - accuracy: 0.6171 - val_loss: 1.0465 - val_accuracy: 0.5643\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9117 - accuracy: 0.6195 - val_loss: 1.0393 - val_accuracy: 0.5520\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9116 - accuracy: 0.6208 - val_loss: 1.0504 - val_accuracy: 0.5571\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9069 - accuracy: 0.6171 - val_loss: 1.0379 - val_accuracy: 0.5510\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9026 - accuracy: 0.6178 - val_loss: 1.0458 - val_accuracy: 0.5541\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8984 - accuracy: 0.6191 - val_loss: 1.0383 - val_accuracy: 0.5510\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8923 - accuracy: 0.6290 - val_loss: 1.0413 - val_accuracy: 0.5531\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8873 - accuracy: 0.6263 - val_loss: 1.0423 - val_accuracy: 0.5561\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8828 - accuracy: 0.6338 - val_loss: 1.0392 - val_accuracy: 0.5490\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8794 - accuracy: 0.6317 - val_loss: 1.0387 - val_accuracy: 0.5500\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8757 - accuracy: 0.6334 - val_loss: 1.0435 - val_accuracy: 0.5500\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8711 - accuracy: 0.6361 - val_loss: 1.0392 - val_accuracy: 0.5510\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8675 - accuracy: 0.6399 - val_loss: 1.0384 - val_accuracy: 0.5490\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8637 - accuracy: 0.6372 - val_loss: 1.0504 - val_accuracy: 0.5571\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8621 - accuracy: 0.6457 - val_loss: 1.0445 - val_accuracy: 0.5520\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8585 - accuracy: 0.6440 - val_loss: 1.0427 - val_accuracy: 0.5582\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8553 - accuracy: 0.6413 - val_loss: 1.0464 - val_accuracy: 0.5592\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8526 - accuracy: 0.6501 - val_loss: 1.0561 - val_accuracy: 0.5602\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8479 - accuracy: 0.6443 - val_loss: 1.0467 - val_accuracy: 0.5449\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8454 - accuracy: 0.6484 - val_loss: 1.0459 - val_accuracy: 0.5561\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8390 - accuracy: 0.6569 - val_loss: 1.0607 - val_accuracy: 0.5633\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8370 - accuracy: 0.6562 - val_loss: 1.0587 - val_accuracy: 0.5418\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8366 - accuracy: 0.6590 - val_loss: 1.0838 - val_accuracy: 0.5592\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8423 - accuracy: 0.6555 - val_loss: 1.0738 - val_accuracy: 0.5408\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8500 - accuracy: 0.6426 - val_loss: 1.0542 - val_accuracy: 0.5551\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8332 - accuracy: 0.6572 - val_loss: 1.0642 - val_accuracy: 0.5551\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8256 - accuracy: 0.6607 - val_loss: 1.0572 - val_accuracy: 0.5531\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8159 - accuracy: 0.6715 - val_loss: 1.0707 - val_accuracy: 0.5500\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8163 - accuracy: 0.6675 - val_loss: 1.0555 - val_accuracy: 0.5582\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8094 - accuracy: 0.6692 - val_loss: 1.0610 - val_accuracy: 0.5571\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8080 - accuracy: 0.6760 - val_loss: 1.0669 - val_accuracy: 0.5714\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8047 - accuracy: 0.6739 - val_loss: 1.0611 - val_accuracy: 0.5541\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7979 - accuracy: 0.6787 - val_loss: 1.0643 - val_accuracy: 0.5735\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7924 - accuracy: 0.6848 - val_loss: 1.0666 - val_accuracy: 0.5633\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7896 - accuracy: 0.6801 - val_loss: 1.0665 - val_accuracy: 0.5724\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7864 - accuracy: 0.6790 - val_loss: 1.0653 - val_accuracy: 0.5663\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7845 - accuracy: 0.6909 - val_loss: 1.0911 - val_accuracy: 0.5541\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7823 - accuracy: 0.6852 - val_loss: 1.0722 - val_accuracy: 0.5684\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7780 - accuracy: 0.6886 - val_loss: 1.0791 - val_accuracy: 0.5755\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7766 - accuracy: 0.6923 - val_loss: 1.0894 - val_accuracy: 0.5561\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7800 - accuracy: 0.6838 - val_loss: 1.0736 - val_accuracy: 0.5724\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7791 - accuracy: 0.6807 - val_loss: 1.0840 - val_accuracy: 0.5520\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7732 - accuracy: 0.6882 - val_loss: 1.0966 - val_accuracy: 0.5582\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7626 - accuracy: 0.6974 - val_loss: 1.0909 - val_accuracy: 0.5469\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7623 - accuracy: 0.6984 - val_loss: 1.0812 - val_accuracy: 0.5653\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7547 - accuracy: 0.6978 - val_loss: 1.0849 - val_accuracy: 0.5653\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7497 - accuracy: 0.6978 - val_loss: 1.0834 - val_accuracy: 0.5673\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7470 - accuracy: 0.7076 - val_loss: 1.0994 - val_accuracy: 0.5622\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7470 - accuracy: 0.6998 - val_loss: 1.0863 - val_accuracy: 0.5612\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7469 - accuracy: 0.7025 - val_loss: 1.0994 - val_accuracy: 0.5684\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7455 - accuracy: 0.7090 - val_loss: 1.1161 - val_accuracy: 0.5582\n",
      "Epoch 101/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7476 - accuracy: 0.7012 - val_loss: 1.1022 - val_accuracy: 0.5673\n",
      "Epoch 102/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7406 - accuracy: 0.7073 - val_loss: 1.0966 - val_accuracy: 0.5684\n",
      "Epoch 103/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7298 - accuracy: 0.7131 - val_loss: 1.1066 - val_accuracy: 0.5592\n",
      "Epoch 104/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7269 - accuracy: 0.7097 - val_loss: 1.1057 - val_accuracy: 0.5592\n",
      "Epoch 105/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7270 - accuracy: 0.7138 - val_loss: 1.1094 - val_accuracy: 0.5643\n",
      "Epoch 106/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7234 - accuracy: 0.7148 - val_loss: 1.1065 - val_accuracy: 0.5653\n",
      "Epoch 107/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7244 - accuracy: 0.7172 - val_loss: 1.1378 - val_accuracy: 0.5633\n",
      "Epoch 108/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7277 - accuracy: 0.7134 - val_loss: 1.1088 - val_accuracy: 0.5633\n",
      "Epoch 109/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7178 - accuracy: 0.7178 - val_loss: 1.1155 - val_accuracy: 0.5449\n",
      "Epoch 110/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7229 - accuracy: 0.7148 - val_loss: 1.1270 - val_accuracy: 0.5694\n",
      "Epoch 111/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7168 - accuracy: 0.7127 - val_loss: 1.1280 - val_accuracy: 0.5704\n",
      "Epoch 112/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7081 - accuracy: 0.7195 - val_loss: 1.1175 - val_accuracy: 0.5704\n",
      "Epoch 113/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7141 - accuracy: 0.7189 - val_loss: 1.1115 - val_accuracy: 0.5673\n",
      "Epoch 114/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7056 - accuracy: 0.7158 - val_loss: 1.1310 - val_accuracy: 0.5735\n",
      "Epoch 115/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6943 - accuracy: 0.7308 - val_loss: 1.1241 - val_accuracy: 0.5633\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6921 - accuracy: 0.7314 - val_loss: 1.1255 - val_accuracy: 0.5673\n",
      "Epoch 117/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6972 - accuracy: 0.7233 - val_loss: 1.1523 - val_accuracy: 0.5653\n",
      "Epoch 118/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6946 - accuracy: 0.7321 - val_loss: 1.1347 - val_accuracy: 0.5551\n",
      "Epoch 119/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6857 - accuracy: 0.7311 - val_loss: 1.1347 - val_accuracy: 0.5653\n",
      "Epoch 120/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6852 - accuracy: 0.7362 - val_loss: 1.1337 - val_accuracy: 0.5694\n",
      "Epoch 121/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6806 - accuracy: 0.7427 - val_loss: 1.1453 - val_accuracy: 0.5786\n",
      "Epoch 122/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6805 - accuracy: 0.7389 - val_loss: 1.1465 - val_accuracy: 0.5776\n",
      "Epoch 123/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6777 - accuracy: 0.7396 - val_loss: 1.1407 - val_accuracy: 0.5735\n",
      "Epoch 124/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6702 - accuracy: 0.7427 - val_loss: 1.1420 - val_accuracy: 0.5714\n",
      "Epoch 125/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6692 - accuracy: 0.7488 - val_loss: 1.1583 - val_accuracy: 0.5684\n",
      "Epoch 126/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6803 - accuracy: 0.7345 - val_loss: 1.1531 - val_accuracy: 0.5816\n",
      "Epoch 127/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6650 - accuracy: 0.7485 - val_loss: 1.1531 - val_accuracy: 0.5684\n",
      "Epoch 128/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6612 - accuracy: 0.7430 - val_loss: 1.1630 - val_accuracy: 0.5755\n",
      "Epoch 129/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6604 - accuracy: 0.7549 - val_loss: 1.1628 - val_accuracy: 0.5663\n",
      "Epoch 130/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6607 - accuracy: 0.7502 - val_loss: 1.1678 - val_accuracy: 0.5776\n",
      "Epoch 131/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6586 - accuracy: 0.7532 - val_loss: 1.1785 - val_accuracy: 0.5673\n",
      "Epoch 132/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6611 - accuracy: 0.7427 - val_loss: 1.1849 - val_accuracy: 0.5633\n",
      "Epoch 133/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6574 - accuracy: 0.7566 - val_loss: 1.1700 - val_accuracy: 0.5684\n",
      "Epoch 134/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6445 - accuracy: 0.7580 - val_loss: 1.1760 - val_accuracy: 0.5755\n",
      "Epoch 135/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6440 - accuracy: 0.7522 - val_loss: 1.1922 - val_accuracy: 0.5745\n",
      "Epoch 136/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6528 - accuracy: 0.7505 - val_loss: 1.2029 - val_accuracy: 0.5551\n",
      "Epoch 137/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6497 - accuracy: 0.7481 - val_loss: 1.1756 - val_accuracy: 0.5765\n",
      "Epoch 138/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6332 - accuracy: 0.7665 - val_loss: 1.1902 - val_accuracy: 0.5776\n",
      "Epoch 139/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6369 - accuracy: 0.7600 - val_loss: 1.1836 - val_accuracy: 0.5724\n",
      "Epoch 140/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6353 - accuracy: 0.7621 - val_loss: 1.1928 - val_accuracy: 0.5694\n",
      "Epoch 141/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6302 - accuracy: 0.7658 - val_loss: 1.1986 - val_accuracy: 0.5765\n",
      "Epoch 142/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6280 - accuracy: 0.7645 - val_loss: 1.1915 - val_accuracy: 0.5735\n",
      "Epoch 143/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6274 - accuracy: 0.7679 - val_loss: 1.1968 - val_accuracy: 0.5765\n",
      "Epoch 144/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6212 - accuracy: 0.7685 - val_loss: 1.2024 - val_accuracy: 0.5755\n",
      "Epoch 145/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6213 - accuracy: 0.7723 - val_loss: 1.2015 - val_accuracy: 0.5776\n",
      "Epoch 146/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6192 - accuracy: 0.7648 - val_loss: 1.2048 - val_accuracy: 0.5684\n",
      "Epoch 147/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6144 - accuracy: 0.7764 - val_loss: 1.2076 - val_accuracy: 0.5786\n",
      "Epoch 148/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6119 - accuracy: 0.7760 - val_loss: 1.2136 - val_accuracy: 0.5745\n",
      "Epoch 149/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6085 - accuracy: 0.7699 - val_loss: 1.2316 - val_accuracy: 0.5857\n",
      "Epoch 150/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6133 - accuracy: 0.7679 - val_loss: 1.2251 - val_accuracy: 0.5765\n",
      "Epoch 151/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6203 - accuracy: 0.7631 - val_loss: 1.1988 - val_accuracy: 0.5694\n",
      "Epoch 152/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6154 - accuracy: 0.7668 - val_loss: 1.2449 - val_accuracy: 0.5816\n",
      "Epoch 153/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6097 - accuracy: 0.7720 - val_loss: 1.2305 - val_accuracy: 0.5765\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(patience = 100)\n",
    "filepath = \"./model/white_wine{epoch:04d}__{val_loss:.4f}.keras\"\n",
    "model_save = ModelCheckpoint(filepath = filepath, save_best_only=True)\n",
    "history2 = model2.fit(X_train, y_train, epochs = 10000, batch_size = 500, validation_data = (X_valid, y_valid), callbacks = [early_stop, model_save]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c31dfd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:18:22.236692: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:18:22.352846: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:18:22.352917: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "wine_best_model = load_model(\"./model/white_wine0001__1.8904.keras\")\n",
    "wine_pred = wine_best_model.predict(X_test)\n",
    "wine_pred = pd.DataFrame(wine_pred, columns = y_valid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96e2f87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139927</td>\n",
       "      <td>0.142714</td>\n",
       "      <td>0.142892</td>\n",
       "      <td>0.147985</td>\n",
       "      <td>0.145178</td>\n",
       "      <td>0.143190</td>\n",
       "      <td>0.138113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.140001</td>\n",
       "      <td>0.141627</td>\n",
       "      <td>0.147060</td>\n",
       "      <td>0.146107</td>\n",
       "      <td>0.144495</td>\n",
       "      <td>0.141354</td>\n",
       "      <td>0.139356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132888</td>\n",
       "      <td>0.137718</td>\n",
       "      <td>0.144653</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>0.156503</td>\n",
       "      <td>0.145591</td>\n",
       "      <td>0.135797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130727</td>\n",
       "      <td>0.142734</td>\n",
       "      <td>0.138916</td>\n",
       "      <td>0.153043</td>\n",
       "      <td>0.157908</td>\n",
       "      <td>0.147233</td>\n",
       "      <td>0.129440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.136807</td>\n",
       "      <td>0.141923</td>\n",
       "      <td>0.142586</td>\n",
       "      <td>0.150979</td>\n",
       "      <td>0.148929</td>\n",
       "      <td>0.144072</td>\n",
       "      <td>0.134705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.127228</td>\n",
       "      <td>0.143253</td>\n",
       "      <td>0.158703</td>\n",
       "      <td>0.142769</td>\n",
       "      <td>0.150106</td>\n",
       "      <td>0.139710</td>\n",
       "      <td>0.138231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.121102</td>\n",
       "      <td>0.131622</td>\n",
       "      <td>0.143368</td>\n",
       "      <td>0.150179</td>\n",
       "      <td>0.176346</td>\n",
       "      <td>0.149305</td>\n",
       "      <td>0.128077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.130852</td>\n",
       "      <td>0.134992</td>\n",
       "      <td>0.153660</td>\n",
       "      <td>0.158598</td>\n",
       "      <td>0.145547</td>\n",
       "      <td>0.147337</td>\n",
       "      <td>0.129014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.120754</td>\n",
       "      <td>0.146305</td>\n",
       "      <td>0.138285</td>\n",
       "      <td>0.153421</td>\n",
       "      <td>0.161909</td>\n",
       "      <td>0.153170</td>\n",
       "      <td>0.126156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.130285</td>\n",
       "      <td>0.135692</td>\n",
       "      <td>0.158764</td>\n",
       "      <td>0.148274</td>\n",
       "      <td>0.145903</td>\n",
       "      <td>0.145227</td>\n",
       "      <td>0.135856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            3         4         5         6         7         8         9\n",
       "0    0.139927  0.142714  0.142892  0.147985  0.145178  0.143190  0.138113\n",
       "1    0.140001  0.141627  0.147060  0.146107  0.144495  0.141354  0.139356\n",
       "2    0.132888  0.137718  0.144653  0.146849  0.156503  0.145591  0.135797\n",
       "3    0.130727  0.142734  0.138916  0.153043  0.157908  0.147233  0.129440\n",
       "4    0.136807  0.141923  0.142586  0.150979  0.148929  0.144072  0.134705\n",
       "..        ...       ...       ...       ...       ...       ...       ...\n",
       "975  0.127228  0.143253  0.158703  0.142769  0.150106  0.139710  0.138231\n",
       "976  0.121102  0.131622  0.143368  0.150179  0.176346  0.149305  0.128077\n",
       "977  0.130852  0.134992  0.153660  0.158598  0.145547  0.147337  0.129014\n",
       "978  0.120754  0.146305  0.138285  0.153421  0.161909  0.153170  0.126156\n",
       "979  0.130285  0.135692  0.158764  0.148274  0.145903  0.145227  0.135856\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "771b174a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      7\n",
       "3      7\n",
       "4      5\n",
       "      ..\n",
       "975    6\n",
       "976    4\n",
       "977    5\n",
       "978    6\n",
       "979    6\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_class = y_test.idxmax(axis = 1)\n",
    "y_test_class = y_test_class.reset_index(drop=True)\n",
    "y_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f7fffb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      5\n",
       "2      7\n",
       "3      7\n",
       "4      6\n",
       "      ..\n",
       "975    5\n",
       "976    7\n",
       "977    6\n",
       "978    7\n",
       "979    5\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred_class = wine_pred.idxmax(axis=1)\n",
    "wine_pred_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "148a7aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.41      0.39      0.40       291\n",
      "           6       0.42      0.22      0.29       440\n",
      "           7       0.22      0.60      0.32       176\n",
      "           8       0.00      0.00      0.00        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.32       980\n",
      "   macro avg       0.15      0.17      0.14       980\n",
      "weighted avg       0.35      0.32      0.31       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, wine_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4dcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57676f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e196e3",
   "metadata": {},
   "source": [
    "### XGB로 비교 분석\n",
    "* Gradient Boosting 기반으로 함 \n",
    "* 부스팅 기법은 여러 약한 모델을 순차적으로 학습하고, 이전 모델이 만든 오차를 줄이는 방식으로 새로운 모델을 추가함. \n",
    "* 즉, 각 새로운 모델은 이전 모델들이 예측하지 못한 부분을 더 잘 예측하려고 시도함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dcde76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfe8a398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       6\n",
       "2       6\n",
       "3       6\n",
       "4       6\n",
       "       ..\n",
       "4893    6\n",
       "4894    5\n",
       "4895    6\n",
       "4896    7\n",
       "4897    6\n",
       "Name: quality, Length: 4898, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ec522d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1cc7218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 4, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y2_labeled = le.fit_transform(y2)\n",
    "y2_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff009c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "833fbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_scaled, y2_labeled, test_size=0.4, stratify=y2_labeled, random_state=10)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_valid2, y_valid2, test_size=0.5, stratify=y_valid2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0199ad57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca81e4d0",
   "metadata": {},
   "source": [
    "## ADASYN\n",
    "* Adaptive Synthetic Sampling Approach for Imbalanced Learning \n",
    "* 불균형 데이터 문제를 해결하기 위한 오버샘플링 기법 중 하나 \n",
    "* 불균형 데이터 : 클래스 간 데이터 수가 크게 차이 나는 상황을 말함 \n",
    "* ADASYN 은 소수 클래스의 데이터를 증가시켜 불균형 문제를 완화함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cb477e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Using cached imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd85a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "870f64e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adasyn = ADASYN(random_state=10, n_neighbors=2, n_jobs=-1)\n",
    "X_train2_adasyn, y_train2_adasyn = adasyn.fit_resample(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5e872fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.400000</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-0.353659</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.521739</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>-0.381496</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.134146</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>1.308966</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>-0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.727273</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.217391</td>\n",
       "      <td>-0.355932</td>\n",
       "      <td>0.073101</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.341463</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>-0.478261</td>\n",
       "      <td>-0.576271</td>\n",
       "      <td>-0.785837</td>\n",
       "      <td>-0.157895</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.916667</td>\n",
       "      <td>-0.280488</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>-0.135593</td>\n",
       "      <td>-0.651057</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9290</th>\n",
       "      <td>1.437013</td>\n",
       "      <td>-0.047538</td>\n",
       "      <td>0.702604</td>\n",
       "      <td>0.126134</td>\n",
       "      <td>-0.716468</td>\n",
       "      <td>-0.282941</td>\n",
       "      <td>-0.040431</td>\n",
       "      <td>-0.003261</td>\n",
       "      <td>0.319006</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.561075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>1.727996</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>0.830979</td>\n",
       "      <td>0.305650</td>\n",
       "      <td>-0.667564</td>\n",
       "      <td>-0.275499</td>\n",
       "      <td>-0.083948</td>\n",
       "      <td>0.248944</td>\n",
       "      <td>0.246936</td>\n",
       "      <td>-0.023361</td>\n",
       "      <td>0.371891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9292</th>\n",
       "      <td>0.523141</td>\n",
       "      <td>-0.135237</td>\n",
       "      <td>0.610880</td>\n",
       "      <td>-0.383995</td>\n",
       "      <td>-0.838843</td>\n",
       "      <td>-0.259792</td>\n",
       "      <td>-0.028155</td>\n",
       "      <td>-0.743358</td>\n",
       "      <td>0.647672</td>\n",
       "      <td>-0.038370</td>\n",
       "      <td>1.159199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9293</th>\n",
       "      <td>0.487635</td>\n",
       "      <td>-0.113718</td>\n",
       "      <td>0.739095</td>\n",
       "      <td>-0.381109</td>\n",
       "      <td>-0.830389</td>\n",
       "      <td>-0.239209</td>\n",
       "      <td>-0.080310</td>\n",
       "      <td>-0.750117</td>\n",
       "      <td>0.703734</td>\n",
       "      <td>-0.089093</td>\n",
       "      <td>1.184116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>1.154337</td>\n",
       "      <td>-0.092887</td>\n",
       "      <td>0.577894</td>\n",
       "      <td>-0.048257</td>\n",
       "      <td>-0.763977</td>\n",
       "      <td>-0.290170</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>-0.248265</td>\n",
       "      <td>0.389019</td>\n",
       "      <td>0.024846</td>\n",
       "      <td>0.744859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9295 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0         -1.400000         -0.181818    -1.166667       -0.353659   0.500000   \n",
       "1          0.300000         -0.727273     0.583333        1.134146   0.571429   \n",
       "2          0.000000         -0.727273    -0.333333        0.560976  -0.285714   \n",
       "3          0.300000         -0.454545     0.416667       -0.341463  -1.214286   \n",
       "4         -0.200000          0.000000    -0.916667       -0.280488  -1.214286   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "9290       1.437013         -0.047538     0.702604        0.126134  -0.716468   \n",
       "9291       1.727996         -0.000856     0.830979        0.305650  -0.667564   \n",
       "9292       0.523141         -0.135237     0.610880       -0.383995  -0.838843   \n",
       "9293       0.487635         -0.113718     0.739095       -0.381109  -0.830389   \n",
       "9294       1.154337         -0.092887     0.577894       -0.048257  -0.763977   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0               -0.521739              0.186441 -0.381496  0.315789   \n",
       "1                0.608696              0.372881  1.308966  0.894737   \n",
       "2               -0.217391             -0.355932  0.073101 -0.368421   \n",
       "3               -0.478261             -0.576271 -0.785837 -0.157895   \n",
       "4                0.608696             -0.135593 -0.651057  0.210526   \n",
       "...                   ...                   ...       ...       ...   \n",
       "9290            -0.282941             -0.040431 -0.003261  0.319006   \n",
       "9291            -0.275499             -0.083948  0.248944  0.246936   \n",
       "9292            -0.259792             -0.028155 -0.743358  0.647672   \n",
       "9293            -0.239209             -0.080310 -0.750117  0.703734   \n",
       "9294            -0.290170              0.001844 -0.248265  0.389019   \n",
       "\n",
       "      sulphates   alcohol  \n",
       "0     -0.071429 -0.052632  \n",
       "1      2.214286 -0.684211  \n",
       "2     -0.142857  0.263158  \n",
       "3     -0.642857  0.526316  \n",
       "4     -0.642857  0.473684  \n",
       "...         ...       ...  \n",
       "9290   0.001091  0.561075  \n",
       "9291  -0.023361  0.371891  \n",
       "9292  -0.038370  1.159199  \n",
       "9293  -0.089093  1.184116  \n",
       "9294   0.024846  0.744859  \n",
       "\n",
       "[9295 rows x 11 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2_adasyn = pd.DataFrame(X_train2_adasyn, columns=X.columns)\n",
    "X_train2_adasyn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed7c096e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1410\n",
       "1    1346\n",
       "5    1345\n",
       "0    1320\n",
       "3    1318\n",
       "6    1317\n",
       "4    1239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2_adasyn = pd.Series(y_train2_adasyn)\n",
    "y_train2_adasyn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c105915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f649e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d0cfc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.14      0.25      0.18         4\n",
      "           4       0.46      0.39      0.43        33\n",
      "           5       0.66      0.62      0.64       291\n",
      "           6       0.64      0.64      0.64       440\n",
      "           7       0.55      0.61      0.58       176\n",
      "           8       0.43      0.46      0.44        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61       980\n",
      "   macro avg       0.41      0.42      0.41       980\n",
      "weighted avg       0.61      0.61      0.61       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth= 5, n_estimators=1000, random_state=10, n_jobs=-1)\n",
    "xgb.fit(X_train2_adasyn, y_train2_adasyn)\n",
    "xgb_pred = xgb.predict(X_valid2)\n",
    "print(classification_report(le.inverse_transform(y_valid2), le.inverse_transform(xgb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea69ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9f007e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42116849",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('quality', axis=1).copy()\n",
    "y = wine['quality'].copy()\n",
    "y2 = wine['quality'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b603e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c63a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd625be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "X_scaled = rs.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5638279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d691c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.4, stratify=y ,random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "388e53a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3ed0133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2938, 11) (980, 11) (980, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "209a3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93611c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "18c78e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(64, input_dim=11, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(64, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f0e72ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 64)                768       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,687\n",
      "Trainable params: 7,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d47deb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2938, 11) (2938, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a8bfb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/6 [====>.........................] - ETA: 2s - loss: 1.9222 - accuracy: 0.2640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:20:46.122816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:20:46.178883: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:20:46.178939: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 51ms/step - loss: 1.8785 - accuracy: 0.2937 - val_loss: 1.8251 - val_accuracy: 0.3000\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.7760 - accuracy: 0.2995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:20:46.348548: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:20:46.377726: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:20:46.377795: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 29ms/step - loss: 1.7760 - accuracy: 0.2995 - val_loss: 1.7137 - val_accuracy: 0.2980\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.6570 - accuracy: 0.2975 - val_loss: 1.5914 - val_accuracy: 0.2980\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.5294 - accuracy: 0.2975 - val_loss: 1.4634 - val_accuracy: 0.3000\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.4057 - accuracy: 0.3199 - val_loss: 1.3623 - val_accuracy: 0.4082\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.3319 - accuracy: 0.4666 - val_loss: 1.3199 - val_accuracy: 0.4704\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.3037 - accuracy: 0.4605 - val_loss: 1.2953 - val_accuracy: 0.4653\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.2654 - accuracy: 0.4850 - val_loss: 1.2692 - val_accuracy: 0.4898\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.2346 - accuracy: 0.5119 - val_loss: 1.2491 - val_accuracy: 0.4990\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.2130 - accuracy: 0.5313 - val_loss: 1.2290 - val_accuracy: 0.5061\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1900 - accuracy: 0.5252 - val_loss: 1.2132 - val_accuracy: 0.5194\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1730 - accuracy: 0.5334 - val_loss: 1.1989 - val_accuracy: 0.5306\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.1560 - accuracy: 0.5466 - val_loss: 1.1831 - val_accuracy: 0.5408\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.1417 - accuracy: 0.5477 - val_loss: 1.1680 - val_accuracy: 0.5367\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.1264 - accuracy: 0.5511 - val_loss: 1.1547 - val_accuracy: 0.5429\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.1124 - accuracy: 0.5521 - val_loss: 1.1389 - val_accuracy: 0.5439\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.1000 - accuracy: 0.5517 - val_loss: 1.1291 - val_accuracy: 0.5418\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0883 - accuracy: 0.5538 - val_loss: 1.1174 - val_accuracy: 0.5459\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0777 - accuracy: 0.5497 - val_loss: 1.1092 - val_accuracy: 0.5367\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0678 - accuracy: 0.5534 - val_loss: 1.1017 - val_accuracy: 0.5429\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0588 - accuracy: 0.5596 - val_loss: 1.0968 - val_accuracy: 0.5480\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0516 - accuracy: 0.5647 - val_loss: 1.0901 - val_accuracy: 0.5408\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0430 - accuracy: 0.5671 - val_loss: 1.0868 - val_accuracy: 0.5439\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0371 - accuracy: 0.5667 - val_loss: 1.0811 - val_accuracy: 0.5408\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0304 - accuracy: 0.5745 - val_loss: 1.0770 - val_accuracy: 0.5418\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.0250 - accuracy: 0.5790 - val_loss: 1.0738 - val_accuracy: 0.5429\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 1.0197 - accuracy: 0.5701 - val_loss: 1.0739 - val_accuracy: 0.5500\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0151 - accuracy: 0.5773 - val_loss: 1.0681 - val_accuracy: 0.5449\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.0110 - accuracy: 0.5752 - val_loss: 1.0720 - val_accuracy: 0.5500\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0099 - accuracy: 0.5756 - val_loss: 1.0666 - val_accuracy: 0.5469\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0032 - accuracy: 0.5776 - val_loss: 1.0651 - val_accuracy: 0.5490\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9980 - accuracy: 0.5824 - val_loss: 1.0595 - val_accuracy: 0.5418\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9952 - accuracy: 0.5796 - val_loss: 1.0572 - val_accuracy: 0.5429\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9900 - accuracy: 0.5773 - val_loss: 1.0586 - val_accuracy: 0.5429\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9833 - accuracy: 0.5820 - val_loss: 1.0521 - val_accuracy: 0.5439\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.9786 - accuracy: 0.5848 - val_loss: 1.0530 - val_accuracy: 0.5500\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9759 - accuracy: 0.5875 - val_loss: 1.0523 - val_accuracy: 0.5480\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.9718 - accuracy: 0.5858 - val_loss: 1.0488 - val_accuracy: 0.5490\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9680 - accuracy: 0.5858 - val_loss: 1.0466 - val_accuracy: 0.5480\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.9665 - accuracy: 0.5834 - val_loss: 1.0472 - val_accuracy: 0.5480\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9617 - accuracy: 0.5922 - val_loss: 1.0484 - val_accuracy: 0.5469\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9578 - accuracy: 0.5933 - val_loss: 1.0446 - val_accuracy: 0.5480\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9549 - accuracy: 0.5912 - val_loss: 1.0465 - val_accuracy: 0.5480\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9501 - accuracy: 0.5963 - val_loss: 1.0446 - val_accuracy: 0.5551\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9461 - accuracy: 0.5956 - val_loss: 1.0471 - val_accuracy: 0.5490\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9441 - accuracy: 0.5929 - val_loss: 1.0433 - val_accuracy: 0.5510\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9405 - accuracy: 0.5990 - val_loss: 1.0486 - val_accuracy: 0.5510\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9384 - accuracy: 0.5946 - val_loss: 1.0455 - val_accuracy: 0.5582\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9330 - accuracy: 0.5977 - val_loss: 1.0467 - val_accuracy: 0.5531\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9301 - accuracy: 0.6089 - val_loss: 1.0468 - val_accuracy: 0.5449\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9273 - accuracy: 0.5997 - val_loss: 1.0449 - val_accuracy: 0.5531\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9245 - accuracy: 0.6079 - val_loss: 1.0483 - val_accuracy: 0.5541\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9202 - accuracy: 0.6106 - val_loss: 1.0451 - val_accuracy: 0.5582\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9216 - accuracy: 0.6113 - val_loss: 1.0442 - val_accuracy: 0.5571\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9151 - accuracy: 0.6099 - val_loss: 1.0474 - val_accuracy: 0.5500\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9113 - accuracy: 0.6164 - val_loss: 1.0478 - val_accuracy: 0.5480\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9096 - accuracy: 0.6130 - val_loss: 1.0477 - val_accuracy: 0.5480\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9044 - accuracy: 0.6174 - val_loss: 1.0495 - val_accuracy: 0.5582\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 14ms/step - loss: 0.9048 - accuracy: 0.6174 - val_loss: 1.0468 - val_accuracy: 0.5469\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9010 - accuracy: 0.6184 - val_loss: 1.0446 - val_accuracy: 0.5520\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8978 - accuracy: 0.6157 - val_loss: 1.0524 - val_accuracy: 0.5510\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8910 - accuracy: 0.6201 - val_loss: 1.0455 - val_accuracy: 0.5480\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8924 - accuracy: 0.6178 - val_loss: 1.0516 - val_accuracy: 0.5531\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8871 - accuracy: 0.6232 - val_loss: 1.0537 - val_accuracy: 0.5592\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8819 - accuracy: 0.6270 - val_loss: 1.0503 - val_accuracy: 0.5561\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8773 - accuracy: 0.6266 - val_loss: 1.0582 - val_accuracy: 0.5571\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8755 - accuracy: 0.6276 - val_loss: 1.0466 - val_accuracy: 0.5602\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8720 - accuracy: 0.6297 - val_loss: 1.0520 - val_accuracy: 0.5520\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8674 - accuracy: 0.6324 - val_loss: 1.0517 - val_accuracy: 0.5531\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8653 - accuracy: 0.6317 - val_loss: 1.0488 - val_accuracy: 0.5592\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8601 - accuracy: 0.6399 - val_loss: 1.0521 - val_accuracy: 0.5571\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8551 - accuracy: 0.6368 - val_loss: 1.0565 - val_accuracy: 0.5500\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8528 - accuracy: 0.6416 - val_loss: 1.0568 - val_accuracy: 0.5622\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8495 - accuracy: 0.6470 - val_loss: 1.0540 - val_accuracy: 0.5520\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8464 - accuracy: 0.6433 - val_loss: 1.0533 - val_accuracy: 0.5480\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8423 - accuracy: 0.6491 - val_loss: 1.0644 - val_accuracy: 0.5561\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8412 - accuracy: 0.6484 - val_loss: 1.0633 - val_accuracy: 0.5612\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8386 - accuracy: 0.6477 - val_loss: 1.0563 - val_accuracy: 0.5520\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8336 - accuracy: 0.6511 - val_loss: 1.0615 - val_accuracy: 0.5500\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8336 - accuracy: 0.6555 - val_loss: 1.0584 - val_accuracy: 0.5469\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8333 - accuracy: 0.6549 - val_loss: 1.0692 - val_accuracy: 0.5582\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8236 - accuracy: 0.6593 - val_loss: 1.0765 - val_accuracy: 0.5531\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8219 - accuracy: 0.6610 - val_loss: 1.0643 - val_accuracy: 0.5510\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8168 - accuracy: 0.6620 - val_loss: 1.0635 - val_accuracy: 0.5500\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8156 - accuracy: 0.6661 - val_loss: 1.0655 - val_accuracy: 0.5531\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8131 - accuracy: 0.6610 - val_loss: 1.0818 - val_accuracy: 0.5612\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8099 - accuracy: 0.6692 - val_loss: 1.0804 - val_accuracy: 0.5612\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8071 - accuracy: 0.6675 - val_loss: 1.0670 - val_accuracy: 0.5582\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8023 - accuracy: 0.6668 - val_loss: 1.0726 - val_accuracy: 0.5408\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8013 - accuracy: 0.6688 - val_loss: 1.0754 - val_accuracy: 0.5480\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8008 - accuracy: 0.6719 - val_loss: 1.0732 - val_accuracy: 0.5612\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7942 - accuracy: 0.6729 - val_loss: 1.1023 - val_accuracy: 0.5673\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.7952 - accuracy: 0.6739 - val_loss: 1.0934 - val_accuracy: 0.5643\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7929 - accuracy: 0.6784 - val_loss: 1.0772 - val_accuracy: 0.5673\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7789 - accuracy: 0.6804 - val_loss: 1.0777 - val_accuracy: 0.5551\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7731 - accuracy: 0.6831 - val_loss: 1.0914 - val_accuracy: 0.5663\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7740 - accuracy: 0.6909 - val_loss: 1.0871 - val_accuracy: 0.5592\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7661 - accuracy: 0.6886 - val_loss: 1.0925 - val_accuracy: 0.5684\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7640 - accuracy: 0.6906 - val_loss: 1.0884 - val_accuracy: 0.5653\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7596 - accuracy: 0.6988 - val_loss: 1.0919 - val_accuracy: 0.5612\n",
      "Epoch 101/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7630 - accuracy: 0.6906 - val_loss: 1.0876 - val_accuracy: 0.5510\n",
      "Epoch 102/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7549 - accuracy: 0.6933 - val_loss: 1.1008 - val_accuracy: 0.5531\n",
      "Epoch 103/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7551 - accuracy: 0.6940 - val_loss: 1.0921 - val_accuracy: 0.5755\n",
      "Epoch 104/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7493 - accuracy: 0.7005 - val_loss: 1.1071 - val_accuracy: 0.5653\n",
      "Epoch 105/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7457 - accuracy: 0.6998 - val_loss: 1.1002 - val_accuracy: 0.5786\n",
      "Epoch 106/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7419 - accuracy: 0.7066 - val_loss: 1.1060 - val_accuracy: 0.5663\n",
      "Epoch 107/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7383 - accuracy: 0.7097 - val_loss: 1.1003 - val_accuracy: 0.5694\n",
      "Epoch 108/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7366 - accuracy: 0.7076 - val_loss: 1.1176 - val_accuracy: 0.5735\n",
      "Epoch 109/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7313 - accuracy: 0.7093 - val_loss: 1.1054 - val_accuracy: 0.5796\n",
      "Epoch 110/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7276 - accuracy: 0.7138 - val_loss: 1.1140 - val_accuracy: 0.5663\n",
      "Epoch 111/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7264 - accuracy: 0.7114 - val_loss: 1.1278 - val_accuracy: 0.5480\n",
      "Epoch 112/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7305 - accuracy: 0.7066 - val_loss: 1.1066 - val_accuracy: 0.5735\n",
      "Epoch 113/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7241 - accuracy: 0.7127 - val_loss: 1.1163 - val_accuracy: 0.5643\n",
      "Epoch 114/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7156 - accuracy: 0.7192 - val_loss: 1.1151 - val_accuracy: 0.5704\n",
      "Epoch 115/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7146 - accuracy: 0.7212 - val_loss: 1.1216 - val_accuracy: 0.5755\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7102 - accuracy: 0.7141 - val_loss: 1.1398 - val_accuracy: 0.5765\n",
      "Epoch 117/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7124 - accuracy: 0.7185 - val_loss: 1.1497 - val_accuracy: 0.5694\n",
      "Epoch 118/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7021 - accuracy: 0.7246 - val_loss: 1.1260 - val_accuracy: 0.5827\n",
      "Epoch 119/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6994 - accuracy: 0.7270 - val_loss: 1.1502 - val_accuracy: 0.5653\n",
      "Epoch 120/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6949 - accuracy: 0.7257 - val_loss: 1.1376 - val_accuracy: 0.5796\n",
      "Epoch 121/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6942 - accuracy: 0.7263 - val_loss: 1.1913 - val_accuracy: 0.5765\n",
      "Epoch 122/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6921 - accuracy: 0.7233 - val_loss: 1.1376 - val_accuracy: 0.5745\n",
      "Epoch 123/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6858 - accuracy: 0.7294 - val_loss: 1.1540 - val_accuracy: 0.5796\n",
      "Epoch 124/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6802 - accuracy: 0.7291 - val_loss: 1.1456 - val_accuracy: 0.5765\n",
      "Epoch 125/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6798 - accuracy: 0.7372 - val_loss: 1.1634 - val_accuracy: 0.5776\n",
      "Epoch 126/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6778 - accuracy: 0.7314 - val_loss: 1.1509 - val_accuracy: 0.5806\n",
      "Epoch 127/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6881 - accuracy: 0.7219 - val_loss: 1.1549 - val_accuracy: 0.5694\n",
      "Epoch 128/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6855 - accuracy: 0.7335 - val_loss: 1.1633 - val_accuracy: 0.5776\n",
      "Epoch 129/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6733 - accuracy: 0.7328 - val_loss: 1.1582 - val_accuracy: 0.5724\n",
      "Epoch 130/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6722 - accuracy: 0.7352 - val_loss: 1.1847 - val_accuracy: 0.5398\n",
      "Epoch 131/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6685 - accuracy: 0.7393 - val_loss: 1.1636 - val_accuracy: 0.5714\n",
      "Epoch 132/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6652 - accuracy: 0.7440 - val_loss: 1.1728 - val_accuracy: 0.5765\n",
      "Epoch 133/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6555 - accuracy: 0.7413 - val_loss: 1.1846 - val_accuracy: 0.5776\n",
      "Epoch 134/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6565 - accuracy: 0.7440 - val_loss: 1.2088 - val_accuracy: 0.5694\n",
      "Epoch 135/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6565 - accuracy: 0.7420 - val_loss: 1.1949 - val_accuracy: 0.5776\n",
      "Epoch 136/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6504 - accuracy: 0.7423 - val_loss: 1.1867 - val_accuracy: 0.5745\n",
      "Epoch 137/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6466 - accuracy: 0.7444 - val_loss: 1.1955 - val_accuracy: 0.5837\n",
      "Epoch 138/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6396 - accuracy: 0.7468 - val_loss: 1.1932 - val_accuracy: 0.5796\n",
      "Epoch 139/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6374 - accuracy: 0.7543 - val_loss: 1.1977 - val_accuracy: 0.5755\n",
      "Epoch 140/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6311 - accuracy: 0.7563 - val_loss: 1.2048 - val_accuracy: 0.5745\n",
      "Epoch 141/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6314 - accuracy: 0.7536 - val_loss: 1.1944 - val_accuracy: 0.5755\n",
      "Epoch 142/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6370 - accuracy: 0.7539 - val_loss: 1.2057 - val_accuracy: 0.5704\n",
      "Epoch 143/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6441 - accuracy: 0.7440 - val_loss: 1.2055 - val_accuracy: 0.5827\n",
      "Epoch 144/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6379 - accuracy: 0.7546 - val_loss: 1.2089 - val_accuracy: 0.5867\n",
      "Epoch 145/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6359 - accuracy: 0.7529 - val_loss: 1.2106 - val_accuracy: 0.5847\n",
      "Epoch 146/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6182 - accuracy: 0.7560 - val_loss: 1.2219 - val_accuracy: 0.5827\n",
      "Epoch 147/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6165 - accuracy: 0.7604 - val_loss: 1.2346 - val_accuracy: 0.5786\n",
      "Epoch 148/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6176 - accuracy: 0.7634 - val_loss: 1.2333 - val_accuracy: 0.5765\n",
      "Epoch 149/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6194 - accuracy: 0.7583 - val_loss: 1.2516 - val_accuracy: 0.5827\n",
      "Epoch 150/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6071 - accuracy: 0.7617 - val_loss: 1.2312 - val_accuracy: 0.5827\n",
      "Epoch 151/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6023 - accuracy: 0.7699 - val_loss: 1.2522 - val_accuracy: 0.5765\n",
      "Epoch 152/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6023 - accuracy: 0.7645 - val_loss: 1.2466 - val_accuracy: 0.5796\n",
      "Epoch 153/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6076 - accuracy: 0.7685 - val_loss: 1.2727 - val_accuracy: 0.5694\n",
      "Epoch 154/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5987 - accuracy: 0.7662 - val_loss: 1.2518 - val_accuracy: 0.5888\n",
      "Epoch 155/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5945 - accuracy: 0.7692 - val_loss: 1.2796 - val_accuracy: 0.5806\n",
      "Epoch 156/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5952 - accuracy: 0.7723 - val_loss: 1.2509 - val_accuracy: 0.5837\n",
      "Epoch 157/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5884 - accuracy: 0.7692 - val_loss: 1.2818 - val_accuracy: 0.5888\n",
      "Epoch 158/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5872 - accuracy: 0.7811 - val_loss: 1.2567 - val_accuracy: 0.5847\n",
      "Epoch 159/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5848 - accuracy: 0.7767 - val_loss: 1.2766 - val_accuracy: 0.5857\n",
      "Epoch 160/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5844 - accuracy: 0.7682 - val_loss: 1.2750 - val_accuracy: 0.5837\n",
      "Epoch 161/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5810 - accuracy: 0.7767 - val_loss: 1.2929 - val_accuracy: 0.5837\n",
      "Epoch 162/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5854 - accuracy: 0.7730 - val_loss: 1.2802 - val_accuracy: 0.5857\n",
      "Epoch 163/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5772 - accuracy: 0.7743 - val_loss: 1.2967 - val_accuracy: 0.5806\n",
      "Epoch 164/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5729 - accuracy: 0.7791 - val_loss: 1.2811 - val_accuracy: 0.5827\n",
      "Epoch 165/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5674 - accuracy: 0.7805 - val_loss: 1.2859 - val_accuracy: 0.5786\n",
      "Epoch 166/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5675 - accuracy: 0.7832 - val_loss: 1.3065 - val_accuracy: 0.5827\n",
      "Epoch 167/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5639 - accuracy: 0.7805 - val_loss: 1.3117 - val_accuracy: 0.5776\n",
      "Epoch 168/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5634 - accuracy: 0.7856 - val_loss: 1.3028 - val_accuracy: 0.5755\n",
      "Epoch 169/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5587 - accuracy: 0.7869 - val_loss: 1.3240 - val_accuracy: 0.5786\n",
      "Epoch 170/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5524 - accuracy: 0.7890 - val_loss: 1.3113 - val_accuracy: 0.5704\n",
      "Epoch 171/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5517 - accuracy: 0.7893 - val_loss: 1.3327 - val_accuracy: 0.5857\n",
      "Epoch 172/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5489 - accuracy: 0.7900 - val_loss: 1.3178 - val_accuracy: 0.5918\n",
      "Epoch 173/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5489 - accuracy: 0.7954 - val_loss: 1.3324 - val_accuracy: 0.5786\n",
      "Epoch 174/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5477 - accuracy: 0.7897 - val_loss: 1.3277 - val_accuracy: 0.5827\n",
      "Epoch 175/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5462 - accuracy: 0.7934 - val_loss: 1.3610 - val_accuracy: 0.5755\n",
      "Epoch 176/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5418 - accuracy: 0.7948 - val_loss: 1.3747 - val_accuracy: 0.5776\n",
      "Epoch 177/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5435 - accuracy: 0.7948 - val_loss: 1.3489 - val_accuracy: 0.5776\n",
      "Epoch 178/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5386 - accuracy: 0.7948 - val_loss: 1.3338 - val_accuracy: 0.5837\n",
      "Epoch 179/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5353 - accuracy: 0.8012 - val_loss: 1.4001 - val_accuracy: 0.5776\n",
      "Epoch 180/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5366 - accuracy: 0.8009 - val_loss: 1.3682 - val_accuracy: 0.5837\n",
      "Epoch 181/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5362 - accuracy: 0.7944 - val_loss: 1.3609 - val_accuracy: 0.5786\n",
      "Epoch 182/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5346 - accuracy: 0.7975 - val_loss: 1.3693 - val_accuracy: 0.5816\n",
      "Epoch 183/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5284 - accuracy: 0.8033 - val_loss: 1.3753 - val_accuracy: 0.5796\n",
      "Epoch 184/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5230 - accuracy: 0.8022 - val_loss: 1.3739 - val_accuracy: 0.5888\n",
      "Epoch 185/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5211 - accuracy: 0.8067 - val_loss: 1.3653 - val_accuracy: 0.5714\n",
      "Epoch 186/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5209 - accuracy: 0.8005 - val_loss: 1.3869 - val_accuracy: 0.5704\n",
      "Epoch 187/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5283 - accuracy: 0.8039 - val_loss: 1.3703 - val_accuracy: 0.5837\n",
      "Epoch 188/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5198 - accuracy: 0.8005 - val_loss: 1.3928 - val_accuracy: 0.5837\n",
      "Epoch 189/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5117 - accuracy: 0.8067 - val_loss: 1.4670 - val_accuracy: 0.5796\n",
      "Epoch 190/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5186 - accuracy: 0.8063 - val_loss: 1.4043 - val_accuracy: 0.5735\n",
      "Epoch 191/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5097 - accuracy: 0.8063 - val_loss: 1.4101 - val_accuracy: 0.5755\n",
      "Epoch 192/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5047 - accuracy: 0.8142 - val_loss: 1.4272 - val_accuracy: 0.5765\n",
      "Epoch 193/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5069 - accuracy: 0.8118 - val_loss: 1.4216 - val_accuracy: 0.5694\n",
      "Epoch 194/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5030 - accuracy: 0.8097 - val_loss: 1.4120 - val_accuracy: 0.5827\n",
      "Epoch 195/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5054 - accuracy: 0.8108 - val_loss: 1.4120 - val_accuracy: 0.5755\n",
      "Epoch 196/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5068 - accuracy: 0.8094 - val_loss: 1.4358 - val_accuracy: 0.5765\n",
      "Epoch 197/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.5026 - accuracy: 0.8210 - val_loss: 1.4618 - val_accuracy: 0.5796\n",
      "Epoch 198/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4992 - accuracy: 0.8152 - val_loss: 1.4912 - val_accuracy: 0.5735\n",
      "Epoch 199/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5017 - accuracy: 0.8063 - val_loss: 1.4669 - val_accuracy: 0.5806\n",
      "Epoch 200/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4943 - accuracy: 0.8182 - val_loss: 1.4650 - val_accuracy: 0.5786\n",
      "Epoch 201/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4906 - accuracy: 0.8193 - val_loss: 1.4271 - val_accuracy: 0.5857\n",
      "Epoch 202/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4857 - accuracy: 0.8199 - val_loss: 1.4624 - val_accuracy: 0.5745\n",
      "Epoch 203/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4854 - accuracy: 0.8186 - val_loss: 1.4854 - val_accuracy: 0.5724\n",
      "Epoch 204/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4825 - accuracy: 0.8159 - val_loss: 1.4785 - val_accuracy: 0.5745\n",
      "Epoch 205/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4852 - accuracy: 0.8186 - val_loss: 1.4746 - val_accuracy: 0.5796\n",
      "Epoch 206/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4780 - accuracy: 0.8247 - val_loss: 1.4849 - val_accuracy: 0.5755\n",
      "Epoch 207/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4852 - accuracy: 0.8203 - val_loss: 1.4588 - val_accuracy: 0.5755\n",
      "Epoch 208/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4901 - accuracy: 0.8125 - val_loss: 1.4649 - val_accuracy: 0.5735\n",
      "Epoch 209/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4820 - accuracy: 0.8210 - val_loss: 1.4750 - val_accuracy: 0.5888\n",
      "Epoch 210/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4908 - accuracy: 0.8131 - val_loss: 1.5448 - val_accuracy: 0.5653\n",
      "Epoch 211/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4822 - accuracy: 0.8230 - val_loss: 1.5517 - val_accuracy: 0.5755\n",
      "Epoch 212/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4723 - accuracy: 0.8203 - val_loss: 1.4853 - val_accuracy: 0.5765\n",
      "Epoch 213/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4645 - accuracy: 0.8264 - val_loss: 1.5114 - val_accuracy: 0.5806\n",
      "Epoch 214/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4607 - accuracy: 0.8298 - val_loss: 1.5115 - val_accuracy: 0.5816\n",
      "Epoch 215/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4592 - accuracy: 0.8268 - val_loss: 1.5425 - val_accuracy: 0.5847\n",
      "Epoch 216/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4576 - accuracy: 0.8322 - val_loss: 1.5133 - val_accuracy: 0.5786\n",
      "Epoch 217/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4530 - accuracy: 0.8305 - val_loss: 1.5345 - val_accuracy: 0.5847\n",
      "Epoch 218/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4521 - accuracy: 0.8329 - val_loss: 1.5532 - val_accuracy: 0.5724\n",
      "Epoch 219/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4518 - accuracy: 0.8356 - val_loss: 1.5392 - val_accuracy: 0.5837\n",
      "Epoch 220/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4507 - accuracy: 0.8308 - val_loss: 1.5114 - val_accuracy: 0.5878\n",
      "Epoch 221/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4567 - accuracy: 0.8298 - val_loss: 1.5619 - val_accuracy: 0.5847\n",
      "Epoch 222/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4554 - accuracy: 0.8305 - val_loss: 1.5560 - val_accuracy: 0.5786\n",
      "Epoch 223/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.4447 - accuracy: 0.8336 - val_loss: 1.5698 - val_accuracy: 0.5806\n",
      "Epoch 224/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4392 - accuracy: 0.8383 - val_loss: 1.5616 - val_accuracy: 0.5857\n",
      "Epoch 225/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4383 - accuracy: 0.8383 - val_loss: 1.5803 - val_accuracy: 0.5776\n",
      "Epoch 226/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4384 - accuracy: 0.8376 - val_loss: 1.5512 - val_accuracy: 0.5847\n",
      "Epoch 227/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4392 - accuracy: 0.8319 - val_loss: 1.5668 - val_accuracy: 0.5918\n",
      "Epoch 228/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4457 - accuracy: 0.8342 - val_loss: 1.6785 - val_accuracy: 0.5735\n",
      "Epoch 229/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4506 - accuracy: 0.8298 - val_loss: 1.6207 - val_accuracy: 0.5806\n",
      "Epoch 230/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4392 - accuracy: 0.8295 - val_loss: 1.5719 - val_accuracy: 0.5888\n",
      "Epoch 231/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4369 - accuracy: 0.8393 - val_loss: 1.6267 - val_accuracy: 0.5704\n",
      "Epoch 232/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4350 - accuracy: 0.8410 - val_loss: 1.5893 - val_accuracy: 0.5867\n",
      "Epoch 233/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4257 - accuracy: 0.8424 - val_loss: 1.5769 - val_accuracy: 0.5888\n",
      "Epoch 234/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4292 - accuracy: 0.8373 - val_loss: 1.5921 - val_accuracy: 0.5816\n",
      "Epoch 235/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4284 - accuracy: 0.8414 - val_loss: 1.6180 - val_accuracy: 0.5867\n",
      "Epoch 236/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4210 - accuracy: 0.8482 - val_loss: 1.6234 - val_accuracy: 0.5796\n",
      "Epoch 237/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4188 - accuracy: 0.8438 - val_loss: 1.6600 - val_accuracy: 0.5827\n",
      "Epoch 238/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4215 - accuracy: 0.8407 - val_loss: 1.6099 - val_accuracy: 0.5878\n",
      "Epoch 239/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4139 - accuracy: 0.8431 - val_loss: 1.6197 - val_accuracy: 0.5765\n",
      "Epoch 240/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4167 - accuracy: 0.8434 - val_loss: 1.6546 - val_accuracy: 0.5837\n",
      "Epoch 241/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4216 - accuracy: 0.8428 - val_loss: 1.7229 - val_accuracy: 0.5745\n",
      "Epoch 242/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4258 - accuracy: 0.8404 - val_loss: 1.6743 - val_accuracy: 0.5714\n",
      "Epoch 243/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4182 - accuracy: 0.8455 - val_loss: 1.6271 - val_accuracy: 0.5796\n",
      "Epoch 244/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.4138 - accuracy: 0.8509 - val_loss: 1.6361 - val_accuracy: 0.5806\n",
      "Epoch 245/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4122 - accuracy: 0.8513 - val_loss: 1.7499 - val_accuracy: 0.5704\n",
      "Epoch 246/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4220 - accuracy: 0.8468 - val_loss: 1.6729 - val_accuracy: 0.5755\n",
      "Epoch 247/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4104 - accuracy: 0.8458 - val_loss: 1.6545 - val_accuracy: 0.5796\n",
      "Epoch 248/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4032 - accuracy: 0.8530 - val_loss: 1.6491 - val_accuracy: 0.5918\n",
      "Epoch 249/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4017 - accuracy: 0.8553 - val_loss: 1.7229 - val_accuracy: 0.5816\n",
      "Epoch 250/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4028 - accuracy: 0.8564 - val_loss: 1.7191 - val_accuracy: 0.5867\n",
      "Epoch 251/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4017 - accuracy: 0.8533 - val_loss: 1.6750 - val_accuracy: 0.5837\n",
      "Epoch 252/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4011 - accuracy: 0.8540 - val_loss: 1.6791 - val_accuracy: 0.5786\n",
      "Epoch 253/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.4098 - accuracy: 0.8428 - val_loss: 1.6897 - val_accuracy: 0.5806\n",
      "Epoch 254/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4059 - accuracy: 0.8543 - val_loss: 1.6821 - val_accuracy: 0.5765\n",
      "Epoch 255/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3901 - accuracy: 0.8601 - val_loss: 1.7678 - val_accuracy: 0.5796\n",
      "Epoch 256/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3901 - accuracy: 0.8587 - val_loss: 1.7382 - val_accuracy: 0.5857\n",
      "Epoch 257/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3892 - accuracy: 0.8611 - val_loss: 1.7189 - val_accuracy: 0.5878\n",
      "Epoch 258/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3825 - accuracy: 0.8635 - val_loss: 1.7207 - val_accuracy: 0.5847\n",
      "Epoch 259/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3823 - accuracy: 0.8618 - val_loss: 1.7442 - val_accuracy: 0.5796\n",
      "Epoch 260/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3840 - accuracy: 0.8659 - val_loss: 1.7605 - val_accuracy: 0.5888\n",
      "Epoch 261/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3816 - accuracy: 0.8632 - val_loss: 1.7635 - val_accuracy: 0.5796\n",
      "Epoch 262/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3765 - accuracy: 0.8656 - val_loss: 1.7533 - val_accuracy: 0.5888\n",
      "Epoch 263/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3746 - accuracy: 0.8628 - val_loss: 1.7510 - val_accuracy: 0.5857\n",
      "Epoch 264/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3731 - accuracy: 0.8666 - val_loss: 1.7536 - val_accuracy: 0.5724\n",
      "Epoch 265/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3773 - accuracy: 0.8645 - val_loss: 1.7518 - val_accuracy: 0.5827\n",
      "Epoch 266/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3797 - accuracy: 0.8594 - val_loss: 1.7699 - val_accuracy: 0.5837\n",
      "Epoch 267/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3728 - accuracy: 0.8652 - val_loss: 1.8275 - val_accuracy: 0.5796\n",
      "Epoch 268/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3741 - accuracy: 0.8666 - val_loss: 1.8005 - val_accuracy: 0.5857\n",
      "Epoch 269/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3769 - accuracy: 0.8591 - val_loss: 1.8828 - val_accuracy: 0.5786\n",
      "Epoch 270/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3887 - accuracy: 0.8540 - val_loss: 1.8359 - val_accuracy: 0.5837\n",
      "Epoch 271/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3700 - accuracy: 0.8679 - val_loss: 1.7696 - val_accuracy: 0.5714\n",
      "Epoch 272/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3735 - accuracy: 0.8628 - val_loss: 1.7863 - val_accuracy: 0.5786\n",
      "Epoch 273/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3620 - accuracy: 0.8730 - val_loss: 1.8414 - val_accuracy: 0.5796\n",
      "Epoch 274/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3591 - accuracy: 0.8734 - val_loss: 1.8623 - val_accuracy: 0.5786\n",
      "Epoch 275/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3616 - accuracy: 0.8696 - val_loss: 1.8465 - val_accuracy: 0.5765\n",
      "Epoch 276/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3561 - accuracy: 0.8730 - val_loss: 1.8576 - val_accuracy: 0.5765\n",
      "Epoch 277/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3555 - accuracy: 0.8751 - val_loss: 1.8265 - val_accuracy: 0.5765\n",
      "Epoch 278/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3547 - accuracy: 0.8754 - val_loss: 1.8706 - val_accuracy: 0.5939\n",
      "Epoch 279/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3495 - accuracy: 0.8795 - val_loss: 1.8767 - val_accuracy: 0.5765\n",
      "Epoch 280/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3467 - accuracy: 0.8758 - val_loss: 1.8616 - val_accuracy: 0.5745\n",
      "Epoch 281/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3479 - accuracy: 0.8751 - val_loss: 1.8538 - val_accuracy: 0.5684\n",
      "Epoch 282/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3496 - accuracy: 0.8751 - val_loss: 1.9216 - val_accuracy: 0.5776\n",
      "Epoch 283/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3448 - accuracy: 0.8795 - val_loss: 1.8818 - val_accuracy: 0.5765\n",
      "Epoch 284/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3501 - accuracy: 0.8741 - val_loss: 1.9115 - val_accuracy: 0.5816\n",
      "Epoch 285/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3443 - accuracy: 0.8802 - val_loss: 1.8972 - val_accuracy: 0.5765\n",
      "Epoch 286/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3419 - accuracy: 0.8781 - val_loss: 1.9480 - val_accuracy: 0.5806\n",
      "Epoch 287/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3386 - accuracy: 0.8795 - val_loss: 1.9384 - val_accuracy: 0.5714\n",
      "Epoch 288/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3365 - accuracy: 0.8819 - val_loss: 1.9115 - val_accuracy: 0.5735\n",
      "Epoch 289/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3409 - accuracy: 0.8795 - val_loss: 1.8967 - val_accuracy: 0.5765\n",
      "Epoch 290/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3341 - accuracy: 0.8863 - val_loss: 1.9492 - val_accuracy: 0.5776\n",
      "Epoch 291/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3368 - accuracy: 0.8819 - val_loss: 1.9993 - val_accuracy: 0.5816\n",
      "Epoch 292/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3466 - accuracy: 0.8741 - val_loss: 2.0572 - val_accuracy: 0.5827\n",
      "Epoch 293/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3559 - accuracy: 0.8696 - val_loss: 1.9840 - val_accuracy: 0.5704\n",
      "Epoch 294/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3446 - accuracy: 0.8754 - val_loss: 1.8853 - val_accuracy: 0.5765\n",
      "Epoch 295/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3475 - accuracy: 0.8764 - val_loss: 1.9356 - val_accuracy: 0.5776\n",
      "Epoch 296/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3493 - accuracy: 0.8686 - val_loss: 2.0476 - val_accuracy: 0.5816\n",
      "Epoch 297/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3394 - accuracy: 0.8802 - val_loss: 2.0783 - val_accuracy: 0.5786\n",
      "Epoch 298/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3396 - accuracy: 0.8768 - val_loss: 1.9768 - val_accuracy: 0.5755\n",
      "Epoch 299/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3306 - accuracy: 0.8826 - val_loss: 1.9387 - val_accuracy: 0.5735\n",
      "Epoch 300/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3337 - accuracy: 0.8802 - val_loss: 2.0046 - val_accuracy: 0.5786\n",
      "Epoch 301/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3282 - accuracy: 0.8829 - val_loss: 2.0442 - val_accuracy: 0.5816\n",
      "Epoch 302/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3196 - accuracy: 0.8918 - val_loss: 2.0049 - val_accuracy: 0.5816\n",
      "Epoch 303/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3180 - accuracy: 0.8907 - val_loss: 1.9870 - val_accuracy: 0.5867\n",
      "Epoch 304/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3146 - accuracy: 0.8897 - val_loss: 2.0069 - val_accuracy: 0.5673\n",
      "Epoch 305/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3138 - accuracy: 0.8901 - val_loss: 2.0335 - val_accuracy: 0.5806\n",
      "Epoch 306/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3121 - accuracy: 0.8887 - val_loss: 2.0357 - val_accuracy: 0.5755\n",
      "Epoch 307/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3073 - accuracy: 0.8965 - val_loss: 2.0782 - val_accuracy: 0.5755\n",
      "Epoch 308/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3088 - accuracy: 0.8938 - val_loss: 2.0579 - val_accuracy: 0.5765\n",
      "Epoch 309/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3072 - accuracy: 0.8952 - val_loss: 2.0429 - val_accuracy: 0.5827\n",
      "Epoch 310/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3063 - accuracy: 0.8924 - val_loss: 2.1138 - val_accuracy: 0.5694\n",
      "Epoch 311/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3091 - accuracy: 0.8931 - val_loss: 2.0895 - val_accuracy: 0.5663\n",
      "Epoch 312/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.3056 - accuracy: 0.8911 - val_loss: 2.0644 - val_accuracy: 0.5745\n",
      "Epoch 313/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.9027 - val_loss: 2.1066 - val_accuracy: 0.5816\n",
      "Epoch 314/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2988 - accuracy: 0.9006 - val_loss: 2.0958 - val_accuracy: 0.5714\n",
      "Epoch 315/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2971 - accuracy: 0.8999 - val_loss: 2.0791 - val_accuracy: 0.5755\n",
      "Epoch 316/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2964 - accuracy: 0.9040 - val_loss: 2.1539 - val_accuracy: 0.5735\n",
      "Epoch 317/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2967 - accuracy: 0.8975 - val_loss: 2.1773 - val_accuracy: 0.5776\n",
      "Epoch 318/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3029 - accuracy: 0.8935 - val_loss: 2.1570 - val_accuracy: 0.5694\n",
      "Epoch 319/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.3010 - accuracy: 0.8955 - val_loss: 2.1119 - val_accuracy: 0.5684\n",
      "Epoch 320/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2932 - accuracy: 0.8996 - val_loss: 2.1165 - val_accuracy: 0.5786\n",
      "Epoch 321/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2907 - accuracy: 0.8986 - val_loss: 2.2220 - val_accuracy: 0.5735\n",
      "Epoch 322/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2939 - accuracy: 0.8996 - val_loss: 2.2350 - val_accuracy: 0.5776\n",
      "Epoch 323/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2902 - accuracy: 0.9027 - val_loss: 2.1256 - val_accuracy: 0.5796\n",
      "Epoch 324/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2969 - accuracy: 0.8938 - val_loss: 2.1866 - val_accuracy: 0.5765\n",
      "Epoch 325/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2925 - accuracy: 0.9030 - val_loss: 2.1867 - val_accuracy: 0.5816\n",
      "Epoch 326/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2868 - accuracy: 0.9023 - val_loss: 2.1965 - val_accuracy: 0.5673\n",
      "Epoch 327/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2820 - accuracy: 0.9071 - val_loss: 2.2191 - val_accuracy: 0.5796\n",
      "Epoch 328/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2857 - accuracy: 0.9040 - val_loss: 2.2562 - val_accuracy: 0.5735\n",
      "Epoch 329/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2798 - accuracy: 0.9084 - val_loss: 2.2217 - val_accuracy: 0.5735\n",
      "Epoch 330/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2766 - accuracy: 0.9108 - val_loss: 2.2745 - val_accuracy: 0.5816\n",
      "Epoch 331/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2837 - accuracy: 0.8996 - val_loss: 2.2122 - val_accuracy: 0.5796\n",
      "Epoch 332/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2763 - accuracy: 0.9115 - val_loss: 2.2398 - val_accuracy: 0.5724\n",
      "Epoch 333/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2734 - accuracy: 0.9118 - val_loss: 2.2112 - val_accuracy: 0.5704\n",
      "Epoch 334/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2693 - accuracy: 0.9135 - val_loss: 2.2949 - val_accuracy: 0.5755\n",
      "Epoch 335/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2720 - accuracy: 0.9108 - val_loss: 2.2426 - val_accuracy: 0.5714\n",
      "Epoch 336/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2681 - accuracy: 0.9122 - val_loss: 2.2874 - val_accuracy: 0.5724\n",
      "Epoch 337/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2709 - accuracy: 0.9098 - val_loss: 2.2983 - val_accuracy: 0.5724\n",
      "Epoch 338/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2734 - accuracy: 0.9050 - val_loss: 2.2905 - val_accuracy: 0.5735\n",
      "Epoch 339/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2668 - accuracy: 0.9125 - val_loss: 2.3365 - val_accuracy: 0.5755\n",
      "Epoch 340/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2663 - accuracy: 0.9095 - val_loss: 2.2745 - val_accuracy: 0.5663\n",
      "Epoch 341/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2659 - accuracy: 0.9091 - val_loss: 2.3578 - val_accuracy: 0.5673\n",
      "Epoch 342/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2613 - accuracy: 0.9166 - val_loss: 2.3246 - val_accuracy: 0.5735\n",
      "Epoch 343/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2589 - accuracy: 0.9146 - val_loss: 2.3166 - val_accuracy: 0.5755\n",
      "Epoch 344/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2576 - accuracy: 0.9159 - val_loss: 2.3246 - val_accuracy: 0.5745\n",
      "Epoch 345/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2583 - accuracy: 0.9159 - val_loss: 2.3239 - val_accuracy: 0.5776\n",
      "Epoch 346/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2650 - accuracy: 0.9095 - val_loss: 2.3784 - val_accuracy: 0.5776\n",
      "Epoch 347/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2581 - accuracy: 0.9142 - val_loss: 2.3296 - val_accuracy: 0.5684\n",
      "Epoch 348/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2593 - accuracy: 0.9132 - val_loss: 2.3485 - val_accuracy: 0.5755\n",
      "Epoch 349/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2670 - accuracy: 0.9112 - val_loss: 2.4593 - val_accuracy: 0.5694\n",
      "Epoch 350/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2850 - accuracy: 0.8941 - val_loss: 2.3334 - val_accuracy: 0.5724\n",
      "Epoch 351/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2732 - accuracy: 0.9044 - val_loss: 2.3394 - val_accuracy: 0.5663\n",
      "Epoch 352/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2701 - accuracy: 0.9054 - val_loss: 2.5591 - val_accuracy: 0.5745\n",
      "Epoch 353/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2705 - accuracy: 0.9010 - val_loss: 2.5681 - val_accuracy: 0.5673\n",
      "Epoch 354/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2710 - accuracy: 0.9044 - val_loss: 2.3976 - val_accuracy: 0.5684\n",
      "Epoch 355/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2586 - accuracy: 0.9125 - val_loss: 2.3649 - val_accuracy: 0.5673\n",
      "Epoch 356/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2574 - accuracy: 0.9112 - val_loss: 2.4098 - val_accuracy: 0.5714\n",
      "Epoch 357/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2571 - accuracy: 0.9156 - val_loss: 2.4335 - val_accuracy: 0.5735\n",
      "Epoch 358/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2555 - accuracy: 0.9146 - val_loss: 2.5564 - val_accuracy: 0.5714\n",
      "Epoch 359/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2544 - accuracy: 0.9132 - val_loss: 2.4170 - val_accuracy: 0.5755\n",
      "Epoch 360/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2468 - accuracy: 0.9190 - val_loss: 2.4362 - val_accuracy: 0.5796\n",
      "Epoch 361/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2476 - accuracy: 0.9176 - val_loss: 2.5273 - val_accuracy: 0.5694\n",
      "Epoch 362/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2418 - accuracy: 0.9238 - val_loss: 2.4939 - val_accuracy: 0.5735\n",
      "Epoch 363/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2358 - accuracy: 0.9282 - val_loss: 2.4713 - val_accuracy: 0.5796\n",
      "Epoch 364/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2364 - accuracy: 0.9268 - val_loss: 2.4772 - val_accuracy: 0.5765\n",
      "Epoch 365/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2357 - accuracy: 0.9238 - val_loss: 2.5560 - val_accuracy: 0.5694\n",
      "Epoch 366/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2327 - accuracy: 0.9251 - val_loss: 2.5917 - val_accuracy: 0.5745\n",
      "Epoch 367/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2364 - accuracy: 0.9231 - val_loss: 2.4944 - val_accuracy: 0.5745\n",
      "Epoch 368/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2367 - accuracy: 0.9221 - val_loss: 2.5169 - val_accuracy: 0.5704\n",
      "Epoch 369/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2323 - accuracy: 0.9258 - val_loss: 2.5208 - val_accuracy: 0.5714\n",
      "Epoch 370/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2407 - accuracy: 0.9190 - val_loss: 2.5917 - val_accuracy: 0.5694\n",
      "Epoch 371/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2328 - accuracy: 0.9238 - val_loss: 2.6274 - val_accuracy: 0.5704\n",
      "Epoch 372/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2348 - accuracy: 0.9234 - val_loss: 2.5955 - val_accuracy: 0.5714\n",
      "Epoch 373/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2265 - accuracy: 0.9282 - val_loss: 2.5668 - val_accuracy: 0.5786\n",
      "Epoch 374/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2247 - accuracy: 0.9312 - val_loss: 2.6965 - val_accuracy: 0.5663\n",
      "Epoch 375/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2299 - accuracy: 0.9227 - val_loss: 2.6230 - val_accuracy: 0.5765\n",
      "Epoch 376/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2305 - accuracy: 0.9258 - val_loss: 2.5253 - val_accuracy: 0.5704\n",
      "Epoch 377/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2357 - accuracy: 0.9221 - val_loss: 2.6533 - val_accuracy: 0.5786\n",
      "Epoch 378/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2364 - accuracy: 0.9183 - val_loss: 2.7891 - val_accuracy: 0.5684\n",
      "Epoch 379/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2444 - accuracy: 0.9190 - val_loss: 2.5546 - val_accuracy: 0.5816\n",
      "Epoch 380/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2504 - accuracy: 0.9227 - val_loss: 2.5695 - val_accuracy: 0.5694\n",
      "Epoch 381/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2405 - accuracy: 0.9200 - val_loss: 2.7335 - val_accuracy: 0.5714\n",
      "Epoch 382/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2258 - accuracy: 0.9248 - val_loss: 2.6942 - val_accuracy: 0.5816\n",
      "Epoch 383/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2327 - accuracy: 0.9227 - val_loss: 2.7094 - val_accuracy: 0.5745\n",
      "Epoch 384/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2317 - accuracy: 0.9265 - val_loss: 2.5850 - val_accuracy: 0.5490\n",
      "Epoch 385/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2627 - accuracy: 0.9061 - val_loss: 2.7880 - val_accuracy: 0.5704\n",
      "Epoch 386/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2387 - accuracy: 0.9190 - val_loss: 2.7444 - val_accuracy: 0.5673\n",
      "Epoch 387/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2293 - accuracy: 0.9214 - val_loss: 2.6192 - val_accuracy: 0.5786\n",
      "Epoch 388/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2299 - accuracy: 0.9210 - val_loss: 2.6608 - val_accuracy: 0.5735\n",
      "Epoch 389/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2278 - accuracy: 0.9255 - val_loss: 2.6860 - val_accuracy: 0.5765\n",
      "Epoch 390/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2180 - accuracy: 0.9299 - val_loss: 2.6957 - val_accuracy: 0.5735\n",
      "Epoch 391/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2191 - accuracy: 0.9282 - val_loss: 2.6728 - val_accuracy: 0.5796\n",
      "Epoch 392/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2110 - accuracy: 0.9353 - val_loss: 2.7959 - val_accuracy: 0.5765\n",
      "Epoch 393/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2143 - accuracy: 0.9340 - val_loss: 2.9052 - val_accuracy: 0.5663\n",
      "Epoch 394/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2214 - accuracy: 0.9268 - val_loss: 2.6857 - val_accuracy: 0.5796\n",
      "Epoch 395/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2135 - accuracy: 0.9316 - val_loss: 2.7044 - val_accuracy: 0.5796\n",
      "Epoch 396/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2138 - accuracy: 0.9333 - val_loss: 2.8853 - val_accuracy: 0.5786\n",
      "Epoch 397/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2135 - accuracy: 0.9309 - val_loss: 2.7744 - val_accuracy: 0.5735\n",
      "Epoch 398/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2077 - accuracy: 0.9319 - val_loss: 2.7216 - val_accuracy: 0.5735\n",
      "Epoch 399/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2181 - accuracy: 0.9316 - val_loss: 2.8421 - val_accuracy: 0.5745\n",
      "Epoch 400/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2058 - accuracy: 0.9343 - val_loss: 2.9108 - val_accuracy: 0.5714\n",
      "Epoch 401/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2023 - accuracy: 0.9353 - val_loss: 2.8188 - val_accuracy: 0.5714\n",
      "Epoch 402/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1960 - accuracy: 0.9425 - val_loss: 2.8090 - val_accuracy: 0.5786\n",
      "Epoch 403/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1958 - accuracy: 0.9404 - val_loss: 2.8114 - val_accuracy: 0.5673\n",
      "Epoch 404/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1943 - accuracy: 0.9435 - val_loss: 2.8009 - val_accuracy: 0.5816\n",
      "Epoch 405/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1953 - accuracy: 0.9415 - val_loss: 2.8910 - val_accuracy: 0.5694\n",
      "Epoch 406/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1981 - accuracy: 0.9370 - val_loss: 2.9024 - val_accuracy: 0.5786\n",
      "Epoch 407/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1932 - accuracy: 0.9408 - val_loss: 2.8446 - val_accuracy: 0.5633\n",
      "Epoch 408/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1957 - accuracy: 0.9404 - val_loss: 2.8052 - val_accuracy: 0.5745\n",
      "Epoch 409/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1976 - accuracy: 0.9367 - val_loss: 2.8023 - val_accuracy: 0.5694\n",
      "Epoch 410/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1992 - accuracy: 0.9391 - val_loss: 2.8655 - val_accuracy: 0.5765\n",
      "Epoch 411/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1990 - accuracy: 0.9398 - val_loss: 3.0045 - val_accuracy: 0.5735\n",
      "Epoch 412/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2004 - accuracy: 0.9381 - val_loss: 3.0626 - val_accuracy: 0.5704\n",
      "Epoch 413/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2034 - accuracy: 0.9326 - val_loss: 2.8277 - val_accuracy: 0.5704\n",
      "Epoch 414/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2002 - accuracy: 0.9418 - val_loss: 2.8549 - val_accuracy: 0.5857\n",
      "Epoch 415/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1928 - accuracy: 0.9387 - val_loss: 2.8458 - val_accuracy: 0.5765\n",
      "Epoch 416/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1918 - accuracy: 0.9391 - val_loss: 2.8657 - val_accuracy: 0.5786\n",
      "Epoch 417/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1947 - accuracy: 0.9398 - val_loss: 3.0087 - val_accuracy: 0.5765\n",
      "Epoch 418/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1940 - accuracy: 0.9408 - val_loss: 2.9482 - val_accuracy: 0.5847\n",
      "Epoch 419/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1908 - accuracy: 0.9387 - val_loss: 2.9436 - val_accuracy: 0.5704\n",
      "Epoch 420/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1860 - accuracy: 0.9455 - val_loss: 2.9291 - val_accuracy: 0.5745\n",
      "Epoch 421/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1845 - accuracy: 0.9466 - val_loss: 2.8623 - val_accuracy: 0.5673\n",
      "Epoch 422/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1904 - accuracy: 0.9442 - val_loss: 3.0112 - val_accuracy: 0.5816\n",
      "Epoch 423/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1840 - accuracy: 0.9432 - val_loss: 2.9925 - val_accuracy: 0.5643\n",
      "Epoch 424/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1836 - accuracy: 0.9432 - val_loss: 2.9555 - val_accuracy: 0.5745\n",
      "Epoch 425/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1803 - accuracy: 0.9476 - val_loss: 2.9688 - val_accuracy: 0.5765\n",
      "Epoch 426/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1763 - accuracy: 0.9486 - val_loss: 3.0634 - val_accuracy: 0.5673\n",
      "Epoch 427/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1765 - accuracy: 0.9472 - val_loss: 3.0161 - val_accuracy: 0.5806\n",
      "Epoch 428/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1759 - accuracy: 0.9479 - val_loss: 2.9408 - val_accuracy: 0.5765\n",
      "Epoch 429/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1752 - accuracy: 0.9500 - val_loss: 3.0315 - val_accuracy: 0.5827\n",
      "Epoch 430/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1752 - accuracy: 0.9479 - val_loss: 3.0310 - val_accuracy: 0.5714\n",
      "Epoch 431/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1737 - accuracy: 0.9493 - val_loss: 3.0713 - val_accuracy: 0.5745\n",
      "Epoch 432/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1759 - accuracy: 0.9483 - val_loss: 3.1443 - val_accuracy: 0.5622\n",
      "Epoch 433/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1765 - accuracy: 0.9479 - val_loss: 3.0347 - val_accuracy: 0.5776\n",
      "Epoch 434/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1719 - accuracy: 0.9483 - val_loss: 3.0745 - val_accuracy: 0.5684\n",
      "Epoch 435/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1702 - accuracy: 0.9496 - val_loss: 3.0812 - val_accuracy: 0.5837\n",
      "Epoch 436/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1709 - accuracy: 0.9503 - val_loss: 3.1520 - val_accuracy: 0.5796\n",
      "Epoch 437/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1707 - accuracy: 0.9486 - val_loss: 3.1161 - val_accuracy: 0.5755\n",
      "Epoch 438/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1660 - accuracy: 0.9500 - val_loss: 3.0663 - val_accuracy: 0.5704\n",
      "Epoch 439/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1719 - accuracy: 0.9493 - val_loss: 3.1227 - val_accuracy: 0.5776\n",
      "Epoch 440/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1729 - accuracy: 0.9483 - val_loss: 3.2554 - val_accuracy: 0.5653\n",
      "Epoch 441/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1767 - accuracy: 0.9438 - val_loss: 3.0781 - val_accuracy: 0.5735\n",
      "Epoch 442/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1739 - accuracy: 0.9483 - val_loss: 3.1011 - val_accuracy: 0.5745\n",
      "Epoch 443/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1655 - accuracy: 0.9506 - val_loss: 3.2411 - val_accuracy: 0.5663\n",
      "Epoch 444/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1677 - accuracy: 0.9510 - val_loss: 3.1805 - val_accuracy: 0.5724\n",
      "Epoch 445/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1625 - accuracy: 0.9530 - val_loss: 3.1194 - val_accuracy: 0.5745\n",
      "Epoch 446/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1600 - accuracy: 0.9530 - val_loss: 3.1750 - val_accuracy: 0.5724\n",
      "Epoch 447/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1594 - accuracy: 0.9530 - val_loss: 3.2327 - val_accuracy: 0.5724\n",
      "Epoch 448/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1617 - accuracy: 0.9523 - val_loss: 3.1989 - val_accuracy: 0.5745\n",
      "Epoch 449/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1556 - accuracy: 0.9568 - val_loss: 3.1901 - val_accuracy: 0.5735\n",
      "Epoch 450/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1573 - accuracy: 0.9530 - val_loss: 3.2081 - val_accuracy: 0.5694\n",
      "Epoch 451/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1589 - accuracy: 0.9547 - val_loss: 3.1731 - val_accuracy: 0.5755\n",
      "Epoch 452/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1557 - accuracy: 0.9547 - val_loss: 3.1903 - val_accuracy: 0.5776\n",
      "Epoch 453/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1577 - accuracy: 0.9547 - val_loss: 3.2796 - val_accuracy: 0.5694\n",
      "Epoch 454/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1542 - accuracy: 0.9554 - val_loss: 3.3111 - val_accuracy: 0.5724\n",
      "Epoch 455/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1555 - accuracy: 0.9544 - val_loss: 3.2594 - val_accuracy: 0.5735\n",
      "Epoch 456/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1537 - accuracy: 0.9568 - val_loss: 3.2558 - val_accuracy: 0.5735\n",
      "Epoch 457/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1548 - accuracy: 0.9554 - val_loss: 3.3279 - val_accuracy: 0.5745\n",
      "Epoch 458/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1556 - accuracy: 0.9537 - val_loss: 3.3112 - val_accuracy: 0.5735\n",
      "Epoch 459/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1521 - accuracy: 0.9558 - val_loss: 3.2876 - val_accuracy: 0.5684\n",
      "Epoch 460/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1501 - accuracy: 0.9575 - val_loss: 3.3791 - val_accuracy: 0.5745\n",
      "Epoch 461/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1539 - accuracy: 0.9568 - val_loss: 3.2959 - val_accuracy: 0.5684\n",
      "Epoch 462/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1529 - accuracy: 0.9554 - val_loss: 3.3036 - val_accuracy: 0.5786\n",
      "Epoch 463/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1520 - accuracy: 0.9585 - val_loss: 3.3417 - val_accuracy: 0.5755\n",
      "Epoch 464/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1509 - accuracy: 0.9558 - val_loss: 3.3265 - val_accuracy: 0.5735\n",
      "Epoch 465/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1508 - accuracy: 0.9578 - val_loss: 3.3439 - val_accuracy: 0.5755\n",
      "Epoch 466/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1506 - accuracy: 0.9575 - val_loss: 3.3366 - val_accuracy: 0.5704\n",
      "Epoch 467/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1503 - accuracy: 0.9575 - val_loss: 3.3382 - val_accuracy: 0.5735\n",
      "Epoch 468/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1477 - accuracy: 0.9585 - val_loss: 3.3676 - val_accuracy: 0.5694\n",
      "Epoch 469/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1507 - accuracy: 0.9544 - val_loss: 3.3717 - val_accuracy: 0.5704\n",
      "Epoch 470/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1527 - accuracy: 0.9558 - val_loss: 3.4865 - val_accuracy: 0.5755\n",
      "Epoch 471/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1498 - accuracy: 0.9581 - val_loss: 3.3348 - val_accuracy: 0.5694\n",
      "Epoch 472/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1489 - accuracy: 0.9561 - val_loss: 3.3289 - val_accuracy: 0.5735\n",
      "Epoch 473/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1518 - accuracy: 0.9571 - val_loss: 3.4312 - val_accuracy: 0.5724\n",
      "Epoch 474/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1535 - accuracy: 0.9527 - val_loss: 3.5466 - val_accuracy: 0.5735\n",
      "Epoch 475/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1464 - accuracy: 0.9602 - val_loss: 3.4840 - val_accuracy: 0.5745\n",
      "Epoch 476/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1521 - accuracy: 0.9496 - val_loss: 3.3984 - val_accuracy: 0.5735\n",
      "Epoch 477/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1452 - accuracy: 0.9595 - val_loss: 3.4779 - val_accuracy: 0.5704\n",
      "Epoch 478/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1458 - accuracy: 0.9588 - val_loss: 3.4766 - val_accuracy: 0.5755\n",
      "Epoch 479/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1499 - accuracy: 0.9588 - val_loss: 3.4115 - val_accuracy: 0.5735\n",
      "Epoch 480/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1546 - accuracy: 0.9517 - val_loss: 3.4517 - val_accuracy: 0.5643\n",
      "Epoch 481/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1432 - accuracy: 0.9592 - val_loss: 3.6346 - val_accuracy: 0.5765\n",
      "Epoch 482/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1522 - accuracy: 0.9513 - val_loss: 3.4007 - val_accuracy: 0.5714\n",
      "Epoch 483/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1516 - accuracy: 0.9554 - val_loss: 3.5188 - val_accuracy: 0.5776\n",
      "Epoch 484/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1453 - accuracy: 0.9578 - val_loss: 3.6786 - val_accuracy: 0.5673\n",
      "Epoch 485/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1478 - accuracy: 0.9571 - val_loss: 3.5233 - val_accuracy: 0.5755\n",
      "Epoch 486/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1450 - accuracy: 0.9605 - val_loss: 3.4907 - val_accuracy: 0.5735\n",
      "Epoch 487/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1500 - accuracy: 0.9541 - val_loss: 3.4982 - val_accuracy: 0.5694\n",
      "Epoch 488/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1567 - accuracy: 0.9517 - val_loss: 3.7245 - val_accuracy: 0.5694\n",
      "Epoch 489/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1548 - accuracy: 0.9513 - val_loss: 3.4865 - val_accuracy: 0.5643\n",
      "Epoch 490/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1561 - accuracy: 0.9523 - val_loss: 3.5875 - val_accuracy: 0.5755\n",
      "Epoch 491/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1530 - accuracy: 0.9517 - val_loss: 3.7270 - val_accuracy: 0.5796\n",
      "Epoch 492/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1479 - accuracy: 0.9551 - val_loss: 3.5892 - val_accuracy: 0.5694\n",
      "Epoch 493/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1401 - accuracy: 0.9595 - val_loss: 3.5334 - val_accuracy: 0.5745\n",
      "Epoch 494/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1325 - accuracy: 0.9656 - val_loss: 3.6747 - val_accuracy: 0.5816\n",
      "Epoch 495/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1319 - accuracy: 0.9612 - val_loss: 3.5882 - val_accuracy: 0.5704\n",
      "Epoch 496/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1292 - accuracy: 0.9653 - val_loss: 3.6211 - val_accuracy: 0.5745\n",
      "Epoch 497/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1269 - accuracy: 0.9670 - val_loss: 3.6203 - val_accuracy: 0.5796\n",
      "Epoch 498/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1266 - accuracy: 0.9636 - val_loss: 3.6025 - val_accuracy: 0.5714\n",
      "Epoch 499/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1258 - accuracy: 0.9673 - val_loss: 3.6127 - val_accuracy: 0.5704\n",
      "Epoch 500/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1271 - accuracy: 0.9646 - val_loss: 3.6908 - val_accuracy: 0.5776\n",
      "Epoch 501/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1295 - accuracy: 0.9646 - val_loss: 3.7105 - val_accuracy: 0.5735\n",
      "Epoch 502/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1287 - accuracy: 0.9632 - val_loss: 3.6630 - val_accuracy: 0.5694\n",
      "Epoch 503/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1354 - accuracy: 0.9602 - val_loss: 3.5507 - val_accuracy: 0.5704\n",
      "Epoch 504/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1341 - accuracy: 0.9612 - val_loss: 3.7703 - val_accuracy: 0.5755\n",
      "Epoch 505/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1373 - accuracy: 0.9615 - val_loss: 3.8093 - val_accuracy: 0.5755\n",
      "Epoch 506/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1446 - accuracy: 0.9541 - val_loss: 3.5521 - val_accuracy: 0.5602\n",
      "Epoch 507/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1442 - accuracy: 0.9602 - val_loss: 3.6778 - val_accuracy: 0.5755\n",
      "Epoch 508/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1371 - accuracy: 0.9585 - val_loss: 3.8159 - val_accuracy: 0.5714\n",
      "Epoch 509/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1286 - accuracy: 0.9646 - val_loss: 3.8037 - val_accuracy: 0.5816\n",
      "Epoch 510/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1302 - accuracy: 0.9639 - val_loss: 3.7492 - val_accuracy: 0.5796\n",
      "Epoch 511/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1306 - accuracy: 0.9643 - val_loss: 3.6437 - val_accuracy: 0.5602\n",
      "Epoch 512/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1245 - accuracy: 0.9632 - val_loss: 3.6848 - val_accuracy: 0.5694\n",
      "Epoch 513/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1243 - accuracy: 0.9656 - val_loss: 3.8324 - val_accuracy: 0.5714\n",
      "Epoch 514/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1214 - accuracy: 0.9639 - val_loss: 3.6902 - val_accuracy: 0.5765\n",
      "Epoch 515/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1185 - accuracy: 0.9673 - val_loss: 3.7864 - val_accuracy: 0.5724\n",
      "Epoch 516/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1147 - accuracy: 0.9670 - val_loss: 3.7911 - val_accuracy: 0.5724\n",
      "Epoch 517/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1148 - accuracy: 0.9666 - val_loss: 3.7660 - val_accuracy: 0.5735\n",
      "Epoch 518/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1152 - accuracy: 0.9704 - val_loss: 3.7913 - val_accuracy: 0.5755\n",
      "Epoch 519/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1136 - accuracy: 0.9687 - val_loss: 3.8116 - val_accuracy: 0.5776\n",
      "Epoch 520/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1113 - accuracy: 0.9707 - val_loss: 3.8223 - val_accuracy: 0.5694\n",
      "Epoch 521/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1130 - accuracy: 0.9694 - val_loss: 3.8581 - val_accuracy: 0.5684\n",
      "Epoch 522/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1133 - accuracy: 0.9687 - val_loss: 3.8664 - val_accuracy: 0.5663\n",
      "Epoch 523/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1108 - accuracy: 0.9721 - val_loss: 3.7957 - val_accuracy: 0.5776\n",
      "Epoch 524/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1116 - accuracy: 0.9704 - val_loss: 3.8610 - val_accuracy: 0.5745\n",
      "Epoch 525/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1092 - accuracy: 0.9711 - val_loss: 3.9358 - val_accuracy: 0.5663\n",
      "Epoch 526/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1148 - accuracy: 0.9677 - val_loss: 3.7878 - val_accuracy: 0.5673\n",
      "Epoch 527/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1144 - accuracy: 0.9683 - val_loss: 3.8550 - val_accuracy: 0.5745\n",
      "Epoch 528/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1107 - accuracy: 0.9721 - val_loss: 3.8737 - val_accuracy: 0.5765\n",
      "Epoch 529/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1083 - accuracy: 0.9704 - val_loss: 3.8849 - val_accuracy: 0.5745\n",
      "Epoch 530/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1087 - accuracy: 0.9694 - val_loss: 3.9747 - val_accuracy: 0.5714\n",
      "Epoch 531/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1169 - accuracy: 0.9680 - val_loss: 3.9952 - val_accuracy: 0.5765\n",
      "Epoch 532/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1198 - accuracy: 0.9687 - val_loss: 3.8486 - val_accuracy: 0.5714\n",
      "Epoch 533/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1191 - accuracy: 0.9663 - val_loss: 3.8899 - val_accuracy: 0.5755\n",
      "Epoch 534/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1196 - accuracy: 0.9643 - val_loss: 4.0836 - val_accuracy: 0.5643\n",
      "Epoch 535/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1187 - accuracy: 0.9670 - val_loss: 4.0013 - val_accuracy: 0.5673\n",
      "Epoch 536/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1146 - accuracy: 0.9663 - val_loss: 3.8508 - val_accuracy: 0.5724\n",
      "Epoch 537/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1192 - accuracy: 0.9670 - val_loss: 3.9156 - val_accuracy: 0.5653\n",
      "Epoch 538/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1158 - accuracy: 0.9670 - val_loss: 4.0967 - val_accuracy: 0.5735\n",
      "Epoch 539/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1141 - accuracy: 0.9694 - val_loss: 3.9542 - val_accuracy: 0.5704\n",
      "Epoch 540/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1100 - accuracy: 0.9711 - val_loss: 4.0013 - val_accuracy: 0.5755\n",
      "Epoch 541/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1088 - accuracy: 0.9697 - val_loss: 4.2512 - val_accuracy: 0.5714\n",
      "Epoch 542/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1230 - accuracy: 0.9680 - val_loss: 4.0554 - val_accuracy: 0.5694\n",
      "Epoch 543/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1187 - accuracy: 0.9680 - val_loss: 3.9249 - val_accuracy: 0.5745\n",
      "Epoch 544/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1285 - accuracy: 0.9629 - val_loss: 4.1524 - val_accuracy: 0.5776\n",
      "Epoch 545/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1351 - accuracy: 0.9592 - val_loss: 4.0654 - val_accuracy: 0.5714\n",
      "Epoch 546/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1192 - accuracy: 0.9636 - val_loss: 3.9139 - val_accuracy: 0.5714\n",
      "Epoch 547/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1228 - accuracy: 0.9639 - val_loss: 4.0574 - val_accuracy: 0.5735\n",
      "Epoch 548/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1131 - accuracy: 0.9700 - val_loss: 3.9751 - val_accuracy: 0.5724\n",
      "Epoch 549/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1109 - accuracy: 0.9663 - val_loss: 4.0811 - val_accuracy: 0.5663\n",
      "Epoch 550/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1089 - accuracy: 0.9711 - val_loss: 4.0346 - val_accuracy: 0.5663\n",
      "Epoch 551/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1103 - accuracy: 0.9700 - val_loss: 4.0255 - val_accuracy: 0.5714\n",
      "Epoch 552/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1062 - accuracy: 0.9714 - val_loss: 3.9993 - val_accuracy: 0.5776\n",
      "Epoch 553/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0994 - accuracy: 0.9748 - val_loss: 4.0893 - val_accuracy: 0.5714\n",
      "Epoch 554/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1003 - accuracy: 0.9728 - val_loss: 4.2011 - val_accuracy: 0.5684\n",
      "Epoch 555/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0984 - accuracy: 0.9755 - val_loss: 4.1313 - val_accuracy: 0.5684\n",
      "Epoch 556/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0982 - accuracy: 0.9748 - val_loss: 4.2014 - val_accuracy: 0.5816\n",
      "Epoch 557/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1039 - accuracy: 0.9711 - val_loss: 4.2318 - val_accuracy: 0.5704\n",
      "Epoch 558/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1040 - accuracy: 0.9728 - val_loss: 4.0715 - val_accuracy: 0.5663\n",
      "Epoch 559/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1057 - accuracy: 0.9694 - val_loss: 4.1834 - val_accuracy: 0.5714\n",
      "Epoch 560/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1048 - accuracy: 0.9717 - val_loss: 4.1271 - val_accuracy: 0.5776\n",
      "Epoch 561/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1038 - accuracy: 0.9721 - val_loss: 4.2002 - val_accuracy: 0.5714\n",
      "Epoch 562/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0976 - accuracy: 0.9758 - val_loss: 4.2404 - val_accuracy: 0.5633\n",
      "Epoch 563/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0952 - accuracy: 0.9752 - val_loss: 4.1376 - val_accuracy: 0.5694\n",
      "Epoch 564/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0919 - accuracy: 0.9765 - val_loss: 4.2397 - val_accuracy: 0.5755\n",
      "Epoch 565/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0918 - accuracy: 0.9758 - val_loss: 4.2117 - val_accuracy: 0.5765\n",
      "Epoch 566/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0929 - accuracy: 0.9745 - val_loss: 4.2110 - val_accuracy: 0.5612\n",
      "Epoch 567/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0939 - accuracy: 0.9762 - val_loss: 4.1228 - val_accuracy: 0.5684\n",
      "Epoch 568/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0937 - accuracy: 0.9782 - val_loss: 4.1577 - val_accuracy: 0.5755\n",
      "Epoch 569/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0919 - accuracy: 0.9765 - val_loss: 4.2353 - val_accuracy: 0.5704\n",
      "Epoch 570/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0887 - accuracy: 0.9772 - val_loss: 4.2108 - val_accuracy: 0.5673\n",
      "Epoch 571/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0888 - accuracy: 0.9782 - val_loss: 4.1685 - val_accuracy: 0.5653\n",
      "Epoch 572/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0910 - accuracy: 0.9779 - val_loss: 4.2200 - val_accuracy: 0.5704\n",
      "Epoch 573/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0894 - accuracy: 0.9769 - val_loss: 4.2837 - val_accuracy: 0.5673\n",
      "Epoch 574/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0875 - accuracy: 0.9779 - val_loss: 4.4576 - val_accuracy: 0.5694\n",
      "Epoch 575/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0893 - accuracy: 0.9786 - val_loss: 4.4464 - val_accuracy: 0.5714\n",
      "Epoch 576/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0932 - accuracy: 0.9745 - val_loss: 4.2631 - val_accuracy: 0.5755\n",
      "Epoch 577/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0921 - accuracy: 0.9769 - val_loss: 4.2487 - val_accuracy: 0.5684\n",
      "Epoch 578/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0923 - accuracy: 0.9752 - val_loss: 4.2339 - val_accuracy: 0.5684\n",
      "Epoch 579/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0896 - accuracy: 0.9775 - val_loss: 4.3439 - val_accuracy: 0.5653\n",
      "Epoch 580/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0887 - accuracy: 0.9769 - val_loss: 4.3303 - val_accuracy: 0.5704\n",
      "Epoch 581/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0897 - accuracy: 0.9782 - val_loss: 4.4167 - val_accuracy: 0.5714\n",
      "Epoch 582/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0881 - accuracy: 0.9765 - val_loss: 4.3570 - val_accuracy: 0.5684\n",
      "Epoch 583/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0861 - accuracy: 0.9772 - val_loss: 4.3654 - val_accuracy: 0.5663\n",
      "Epoch 584/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0883 - accuracy: 0.9782 - val_loss: 4.3889 - val_accuracy: 0.5755\n",
      "Epoch 585/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0873 - accuracy: 0.9772 - val_loss: 4.2956 - val_accuracy: 0.5704\n",
      "Epoch 586/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0856 - accuracy: 0.9789 - val_loss: 4.4569 - val_accuracy: 0.5633\n",
      "Epoch 587/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0828 - accuracy: 0.9796 - val_loss: 4.4430 - val_accuracy: 0.5714\n",
      "Epoch 588/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0822 - accuracy: 0.9799 - val_loss: 4.4592 - val_accuracy: 0.5735\n",
      "Epoch 589/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0811 - accuracy: 0.9809 - val_loss: 4.5025 - val_accuracy: 0.5704\n",
      "Epoch 590/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0810 - accuracy: 0.9813 - val_loss: 4.4496 - val_accuracy: 0.5745\n",
      "Epoch 591/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0805 - accuracy: 0.9816 - val_loss: 4.4227 - val_accuracy: 0.5745\n",
      "Epoch 592/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0785 - accuracy: 0.9820 - val_loss: 4.4842 - val_accuracy: 0.5724\n",
      "Epoch 593/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0784 - accuracy: 0.9806 - val_loss: 4.4125 - val_accuracy: 0.5714\n",
      "Epoch 594/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0820 - accuracy: 0.9803 - val_loss: 4.4710 - val_accuracy: 0.5755\n",
      "Epoch 595/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0807 - accuracy: 0.9803 - val_loss: 4.5098 - val_accuracy: 0.5673\n",
      "Epoch 596/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0786 - accuracy: 0.9809 - val_loss: 4.5253 - val_accuracy: 0.5735\n",
      "Epoch 597/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0782 - accuracy: 0.9830 - val_loss: 4.5137 - val_accuracy: 0.5724\n",
      "Epoch 598/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0776 - accuracy: 0.9792 - val_loss: 4.5538 - val_accuracy: 0.5745\n",
      "Epoch 599/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0796 - accuracy: 0.9792 - val_loss: 4.5309 - val_accuracy: 0.5673\n",
      "Epoch 600/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0796 - accuracy: 0.9796 - val_loss: 4.6183 - val_accuracy: 0.5663\n",
      "Epoch 601/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0794 - accuracy: 0.9796 - val_loss: 4.4620 - val_accuracy: 0.5735\n",
      "Epoch 602/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0814 - accuracy: 0.9799 - val_loss: 4.4884 - val_accuracy: 0.5735\n",
      "Epoch 603/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0811 - accuracy: 0.9792 - val_loss: 4.5024 - val_accuracy: 0.5735\n",
      "Epoch 604/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0829 - accuracy: 0.9806 - val_loss: 4.6132 - val_accuracy: 0.5673\n",
      "Epoch 605/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0786 - accuracy: 0.9796 - val_loss: 4.5081 - val_accuracy: 0.5714\n",
      "Epoch 606/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0776 - accuracy: 0.9833 - val_loss: 4.5026 - val_accuracy: 0.5735\n",
      "Epoch 607/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0773 - accuracy: 0.9823 - val_loss: 4.6405 - val_accuracy: 0.5694\n",
      "Epoch 608/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0773 - accuracy: 0.9820 - val_loss: 4.7837 - val_accuracy: 0.5714\n",
      "Epoch 609/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0833 - accuracy: 0.9755 - val_loss: 4.5015 - val_accuracy: 0.5704\n",
      "Epoch 610/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0854 - accuracy: 0.9789 - val_loss: 4.5847 - val_accuracy: 0.5704\n",
      "Epoch 611/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0851 - accuracy: 0.9786 - val_loss: 4.6321 - val_accuracy: 0.5673\n",
      "Epoch 612/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0888 - accuracy: 0.9762 - val_loss: 4.7009 - val_accuracy: 0.5735\n",
      "Epoch 613/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0882 - accuracy: 0.9789 - val_loss: 4.5263 - val_accuracy: 0.5694\n",
      "Epoch 614/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0880 - accuracy: 0.9765 - val_loss: 4.5865 - val_accuracy: 0.5633\n",
      "Epoch 615/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0884 - accuracy: 0.9786 - val_loss: 4.8652 - val_accuracy: 0.5684\n",
      "Epoch 616/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0877 - accuracy: 0.9755 - val_loss: 4.5646 - val_accuracy: 0.5714\n",
      "Epoch 617/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0802 - accuracy: 0.9789 - val_loss: 4.6150 - val_accuracy: 0.5776\n",
      "Epoch 618/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0755 - accuracy: 0.9813 - val_loss: 4.7091 - val_accuracy: 0.5694\n",
      "Epoch 619/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0769 - accuracy: 0.9813 - val_loss: 4.6612 - val_accuracy: 0.5724\n",
      "Epoch 620/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0744 - accuracy: 0.9826 - val_loss: 4.7266 - val_accuracy: 0.5694\n",
      "Epoch 621/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0741 - accuracy: 0.9823 - val_loss: 4.7629 - val_accuracy: 0.5694\n",
      "Epoch 622/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0703 - accuracy: 0.9830 - val_loss: 4.7760 - val_accuracy: 0.5745\n",
      "Epoch 623/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0717 - accuracy: 0.9830 - val_loss: 4.7068 - val_accuracy: 0.5694\n",
      "Epoch 624/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0711 - accuracy: 0.9837 - val_loss: 4.7091 - val_accuracy: 0.5704\n",
      "Epoch 625/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0711 - accuracy: 0.9833 - val_loss: 4.7496 - val_accuracy: 0.5704\n",
      "Epoch 626/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0705 - accuracy: 0.9840 - val_loss: 4.8537 - val_accuracy: 0.5724\n",
      "Epoch 627/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0753 - accuracy: 0.9820 - val_loss: 4.7795 - val_accuracy: 0.5684\n",
      "Epoch 628/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0809 - accuracy: 0.9799 - val_loss: 4.5820 - val_accuracy: 0.5612\n",
      "Epoch 629/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0977 - accuracy: 0.9738 - val_loss: 4.8895 - val_accuracy: 0.5582\n",
      "Epoch 630/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1257 - accuracy: 0.9609 - val_loss: 4.6140 - val_accuracy: 0.5480\n",
      "Epoch 631/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1593 - accuracy: 0.9455 - val_loss: 5.2674 - val_accuracy: 0.5612\n",
      "Epoch 632/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1895 - accuracy: 0.9398 - val_loss: 4.9671 - val_accuracy: 0.5694\n",
      "Epoch 633/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1349 - accuracy: 0.9513 - val_loss: 4.7850 - val_accuracy: 0.5653\n",
      "Epoch 634/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1038 - accuracy: 0.9721 - val_loss: 4.8750 - val_accuracy: 0.5714\n",
      "Epoch 635/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0989 - accuracy: 0.9721 - val_loss: 4.7370 - val_accuracy: 0.5704\n",
      "Epoch 636/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1004 - accuracy: 0.9700 - val_loss: 4.7322 - val_accuracy: 0.5745\n",
      "Epoch 637/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0854 - accuracy: 0.9792 - val_loss: 4.9635 - val_accuracy: 0.5561\n",
      "Epoch 638/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0873 - accuracy: 0.9755 - val_loss: 4.7691 - val_accuracy: 0.5724\n",
      "Epoch 639/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0762 - accuracy: 0.9806 - val_loss: 4.7270 - val_accuracy: 0.5745\n",
      "Epoch 640/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0734 - accuracy: 0.9833 - val_loss: 4.8854 - val_accuracy: 0.5622\n",
      "Epoch 641/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0752 - accuracy: 0.9816 - val_loss: 4.8809 - val_accuracy: 0.5653\n",
      "Epoch 642/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0713 - accuracy: 0.9820 - val_loss: 4.8677 - val_accuracy: 0.5735\n",
      "Epoch 643/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0677 - accuracy: 0.9830 - val_loss: 4.8081 - val_accuracy: 0.5653\n",
      "Epoch 644/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0679 - accuracy: 0.9826 - val_loss: 4.8347 - val_accuracy: 0.5735\n",
      "Epoch 645/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0648 - accuracy: 0.9837 - val_loss: 4.8538 - val_accuracy: 0.5663\n",
      "Epoch 646/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0631 - accuracy: 0.9840 - val_loss: 4.8265 - val_accuracy: 0.5694\n",
      "Epoch 647/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0633 - accuracy: 0.9843 - val_loss: 4.8963 - val_accuracy: 0.5684\n",
      "Epoch 648/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0631 - accuracy: 0.9854 - val_loss: 4.8951 - val_accuracy: 0.5673\n",
      "Epoch 649/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0629 - accuracy: 0.9854 - val_loss: 4.9603 - val_accuracy: 0.5673\n",
      "Epoch 650/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0631 - accuracy: 0.9860 - val_loss: 4.8336 - val_accuracy: 0.5694\n",
      "Epoch 651/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0620 - accuracy: 0.9860 - val_loss: 4.9586 - val_accuracy: 0.5653\n",
      "Epoch 652/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0619 - accuracy: 0.9847 - val_loss: 4.9194 - val_accuracy: 0.5684\n",
      "Epoch 653/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0631 - accuracy: 0.9857 - val_loss: 4.9414 - val_accuracy: 0.5663\n",
      "Epoch 654/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0671 - accuracy: 0.9837 - val_loss: 4.8676 - val_accuracy: 0.5633\n",
      "Epoch 655/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0690 - accuracy: 0.9840 - val_loss: 4.8922 - val_accuracy: 0.5622\n",
      "Epoch 656/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0660 - accuracy: 0.9837 - val_loss: 4.9411 - val_accuracy: 0.5684\n",
      "Epoch 657/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0679 - accuracy: 0.9837 - val_loss: 4.9164 - val_accuracy: 0.5735\n",
      "Epoch 658/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0644 - accuracy: 0.9857 - val_loss: 5.0323 - val_accuracy: 0.5684\n",
      "Epoch 659/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0647 - accuracy: 0.9840 - val_loss: 5.0538 - val_accuracy: 0.5704\n",
      "Epoch 660/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0627 - accuracy: 0.9843 - val_loss: 5.1124 - val_accuracy: 0.5704\n",
      "Epoch 661/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0598 - accuracy: 0.9860 - val_loss: 5.0487 - val_accuracy: 0.5633\n",
      "Epoch 662/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0603 - accuracy: 0.9850 - val_loss: 5.0366 - val_accuracy: 0.5684\n",
      "Epoch 663/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0615 - accuracy: 0.9857 - val_loss: 5.0139 - val_accuracy: 0.5765\n",
      "Epoch 664/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0605 - accuracy: 0.9857 - val_loss: 5.0354 - val_accuracy: 0.5663\n",
      "Epoch 665/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0574 - accuracy: 0.9850 - val_loss: 5.0600 - val_accuracy: 0.5684\n",
      "Epoch 666/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0577 - accuracy: 0.9871 - val_loss: 5.0547 - val_accuracy: 0.5724\n",
      "Epoch 667/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0573 - accuracy: 0.9877 - val_loss: 5.1024 - val_accuracy: 0.5663\n",
      "Epoch 668/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0589 - accuracy: 0.9871 - val_loss: 5.0526 - val_accuracy: 0.5745\n",
      "Epoch 669/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0592 - accuracy: 0.9857 - val_loss: 5.1066 - val_accuracy: 0.5663\n",
      "Epoch 670/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0601 - accuracy: 0.9850 - val_loss: 5.0005 - val_accuracy: 0.5663\n",
      "Epoch 671/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0638 - accuracy: 0.9843 - val_loss: 5.0140 - val_accuracy: 0.5714\n",
      "Epoch 672/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0611 - accuracy: 0.9867 - val_loss: 5.0605 - val_accuracy: 0.5806\n",
      "Epoch 673/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0640 - accuracy: 0.9857 - val_loss: 5.1032 - val_accuracy: 0.5735\n",
      "Epoch 674/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0602 - accuracy: 0.9857 - val_loss: 5.1889 - val_accuracy: 0.5582\n",
      "Epoch 675/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0585 - accuracy: 0.9867 - val_loss: 5.1949 - val_accuracy: 0.5735\n",
      "Epoch 676/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0576 - accuracy: 0.9867 - val_loss: 5.1161 - val_accuracy: 0.5673\n",
      "Epoch 677/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0584 - accuracy: 0.9874 - val_loss: 5.1599 - val_accuracy: 0.5694\n",
      "Epoch 678/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0557 - accuracy: 0.9864 - val_loss: 5.2057 - val_accuracy: 0.5684\n",
      "Epoch 679/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0564 - accuracy: 0.9877 - val_loss: 5.1692 - val_accuracy: 0.5786\n",
      "Epoch 680/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0594 - accuracy: 0.9850 - val_loss: 5.2550 - val_accuracy: 0.5633\n",
      "Epoch 681/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0608 - accuracy: 0.9860 - val_loss: 5.2148 - val_accuracy: 0.5755\n",
      "Epoch 682/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0595 - accuracy: 0.9857 - val_loss: 5.2005 - val_accuracy: 0.5735\n",
      "Epoch 683/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0568 - accuracy: 0.9871 - val_loss: 5.3868 - val_accuracy: 0.5653\n",
      "Epoch 684/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0639 - accuracy: 0.9847 - val_loss: 5.3939 - val_accuracy: 0.5755\n",
      "Epoch 685/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0655 - accuracy: 0.9833 - val_loss: 5.1615 - val_accuracy: 0.5653\n",
      "Epoch 686/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0643 - accuracy: 0.9843 - val_loss: 5.1250 - val_accuracy: 0.5745\n",
      "Epoch 687/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.9840 - val_loss: 5.4251 - val_accuracy: 0.5673\n",
      "Epoch 688/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0665 - accuracy: 0.9837 - val_loss: 5.2874 - val_accuracy: 0.5724\n",
      "Epoch 689/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0611 - accuracy: 0.9850 - val_loss: 5.3598 - val_accuracy: 0.5714\n",
      "Epoch 690/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0627 - accuracy: 0.9854 - val_loss: 5.2018 - val_accuracy: 0.5755\n",
      "Epoch 691/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0606 - accuracy: 0.9860 - val_loss: 5.2423 - val_accuracy: 0.5663\n",
      "Epoch 692/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0577 - accuracy: 0.9867 - val_loss: 5.2174 - val_accuracy: 0.5714\n",
      "Epoch 693/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0584 - accuracy: 0.9854 - val_loss: 5.1807 - val_accuracy: 0.5694\n",
      "Epoch 694/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0643 - accuracy: 0.9837 - val_loss: 5.2372 - val_accuracy: 0.5663\n",
      "Epoch 695/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0628 - accuracy: 0.9826 - val_loss: 5.3916 - val_accuracy: 0.5622\n",
      "Epoch 696/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0629 - accuracy: 0.9854 - val_loss: 5.3499 - val_accuracy: 0.5714\n",
      "Epoch 697/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0565 - accuracy: 0.9847 - val_loss: 5.3269 - val_accuracy: 0.5765\n",
      "Epoch 698/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0565 - accuracy: 0.9864 - val_loss: 5.2398 - val_accuracy: 0.5755\n",
      "Epoch 699/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0537 - accuracy: 0.9888 - val_loss: 5.3169 - val_accuracy: 0.5714\n",
      "Epoch 700/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0519 - accuracy: 0.9871 - val_loss: 5.2709 - val_accuracy: 0.5724\n",
      "Epoch 701/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0506 - accuracy: 0.9901 - val_loss: 5.3553 - val_accuracy: 0.5673\n",
      "Epoch 702/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0503 - accuracy: 0.9888 - val_loss: 5.3141 - val_accuracy: 0.5684\n",
      "Epoch 703/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0508 - accuracy: 0.9888 - val_loss: 5.5145 - val_accuracy: 0.5745\n",
      "Epoch 704/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0545 - accuracy: 0.9874 - val_loss: 5.4041 - val_accuracy: 0.5724\n",
      "Epoch 705/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0523 - accuracy: 0.9891 - val_loss: 5.4271 - val_accuracy: 0.5755\n",
      "Epoch 706/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0497 - accuracy: 0.9888 - val_loss: 5.4118 - val_accuracy: 0.5714\n",
      "Epoch 707/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0497 - accuracy: 0.9888 - val_loss: 5.4632 - val_accuracy: 0.5684\n",
      "Epoch 708/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0496 - accuracy: 0.9894 - val_loss: 5.4237 - val_accuracy: 0.5684\n",
      "Epoch 709/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0479 - accuracy: 0.9881 - val_loss: 5.4252 - val_accuracy: 0.5694\n",
      "Epoch 710/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0477 - accuracy: 0.9888 - val_loss: 5.3745 - val_accuracy: 0.5765\n",
      "Epoch 711/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0467 - accuracy: 0.9898 - val_loss: 5.4094 - val_accuracy: 0.5694\n",
      "Epoch 712/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0482 - accuracy: 0.9894 - val_loss: 5.3714 - val_accuracy: 0.5724\n",
      "Epoch 713/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0523 - accuracy: 0.9877 - val_loss: 5.3662 - val_accuracy: 0.5684\n",
      "Epoch 714/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0488 - accuracy: 0.9891 - val_loss: 5.4126 - val_accuracy: 0.5643\n",
      "Epoch 715/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0520 - accuracy: 0.9891 - val_loss: 5.4892 - val_accuracy: 0.5714\n",
      "Epoch 716/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0501 - accuracy: 0.9898 - val_loss: 5.4113 - val_accuracy: 0.5745\n",
      "Epoch 717/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0490 - accuracy: 0.9894 - val_loss: 5.5335 - val_accuracy: 0.5684\n",
      "Epoch 718/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0487 - accuracy: 0.9888 - val_loss: 5.4362 - val_accuracy: 0.5765\n",
      "Epoch 719/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0508 - accuracy: 0.9881 - val_loss: 5.6370 - val_accuracy: 0.5745\n",
      "Epoch 720/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0565 - accuracy: 0.9881 - val_loss: 5.8796 - val_accuracy: 0.5612\n",
      "Epoch 721/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0730 - accuracy: 0.9806 - val_loss: 5.4255 - val_accuracy: 0.5796\n",
      "Epoch 722/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0713 - accuracy: 0.9803 - val_loss: 5.6435 - val_accuracy: 0.5776\n",
      "Epoch 723/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0656 - accuracy: 0.9792 - val_loss: 5.3943 - val_accuracy: 0.5745\n",
      "Epoch 724/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0602 - accuracy: 0.9854 - val_loss: 5.4874 - val_accuracy: 0.5735\n",
      "Epoch 725/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0556 - accuracy: 0.9881 - val_loss: 5.6446 - val_accuracy: 0.5755\n",
      "Epoch 726/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0538 - accuracy: 0.9874 - val_loss: 5.6820 - val_accuracy: 0.5786\n",
      "Epoch 727/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0509 - accuracy: 0.9881 - val_loss: 5.5888 - val_accuracy: 0.5704\n",
      "Epoch 728/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0503 - accuracy: 0.9888 - val_loss: 5.5992 - val_accuracy: 0.5704\n",
      "Epoch 729/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0490 - accuracy: 0.9884 - val_loss: 5.5758 - val_accuracy: 0.5755\n",
      "Epoch 730/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9891 - val_loss: 5.6630 - val_accuracy: 0.5735\n",
      "Epoch 731/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0453 - accuracy: 0.9891 - val_loss: 5.5962 - val_accuracy: 0.5714\n",
      "Epoch 732/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0448 - accuracy: 0.9908 - val_loss: 5.6430 - val_accuracy: 0.5724\n",
      "Epoch 733/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0470 - accuracy: 0.9884 - val_loss: 5.5845 - val_accuracy: 0.5724\n",
      "Epoch 734/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0486 - accuracy: 0.9901 - val_loss: 5.5022 - val_accuracy: 0.5776\n",
      "Epoch 735/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0563 - accuracy: 0.9864 - val_loss: 5.5654 - val_accuracy: 0.5704\n",
      "Epoch 736/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0612 - accuracy: 0.9837 - val_loss: 5.7384 - val_accuracy: 0.5755\n",
      "Epoch 737/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0559 - accuracy: 0.9860 - val_loss: 5.7252 - val_accuracy: 0.5776\n",
      "Epoch 738/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0523 - accuracy: 0.9877 - val_loss: 5.6988 - val_accuracy: 0.5755\n",
      "Epoch 739/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0497 - accuracy: 0.9877 - val_loss: 5.6830 - val_accuracy: 0.5786\n",
      "Epoch 740/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0452 - accuracy: 0.9888 - val_loss: 5.6650 - val_accuracy: 0.5796\n",
      "Epoch 741/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0456 - accuracy: 0.9901 - val_loss: 5.7007 - val_accuracy: 0.5796\n",
      "Epoch 742/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0439 - accuracy: 0.9905 - val_loss: 5.6775 - val_accuracy: 0.5724\n",
      "Epoch 743/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0420 - accuracy: 0.9898 - val_loss: 5.8073 - val_accuracy: 0.5786\n",
      "Epoch 744/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0421 - accuracy: 0.9901 - val_loss: 5.6597 - val_accuracy: 0.5796\n",
      "Epoch 745/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0411 - accuracy: 0.9918 - val_loss: 5.6677 - val_accuracy: 0.5765\n",
      "Epoch 746/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0431 - accuracy: 0.9908 - val_loss: 5.7201 - val_accuracy: 0.5786\n",
      "Epoch 747/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0409 - accuracy: 0.9898 - val_loss: 5.7748 - val_accuracy: 0.5745\n",
      "Epoch 748/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0427 - accuracy: 0.9918 - val_loss: 5.7586 - val_accuracy: 0.5796\n",
      "Epoch 749/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0420 - accuracy: 0.9905 - val_loss: 5.7865 - val_accuracy: 0.5755\n",
      "Epoch 750/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0421 - accuracy: 0.9918 - val_loss: 5.8766 - val_accuracy: 0.5765\n",
      "Epoch 751/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0439 - accuracy: 0.9901 - val_loss: 5.7714 - val_accuracy: 0.5776\n",
      "Epoch 752/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0411 - accuracy: 0.9918 - val_loss: 5.8500 - val_accuracy: 0.5735\n",
      "Epoch 753/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0392 - accuracy: 0.9922 - val_loss: 5.7703 - val_accuracy: 0.5714\n",
      "Epoch 754/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0395 - accuracy: 0.9918 - val_loss: 5.8359 - val_accuracy: 0.5765\n",
      "Epoch 755/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0422 - accuracy: 0.9901 - val_loss: 5.9032 - val_accuracy: 0.5694\n",
      "Epoch 756/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0397 - accuracy: 0.9918 - val_loss: 5.8240 - val_accuracy: 0.5745\n",
      "Epoch 757/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0379 - accuracy: 0.9932 - val_loss: 5.7361 - val_accuracy: 0.5724\n",
      "Epoch 758/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0373 - accuracy: 0.9922 - val_loss: 5.8132 - val_accuracy: 0.5735\n",
      "Epoch 759/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0400 - accuracy: 0.9922 - val_loss: 5.7683 - val_accuracy: 0.5684\n",
      "Epoch 760/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0406 - accuracy: 0.9929 - val_loss: 5.8300 - val_accuracy: 0.5735\n",
      "Epoch 761/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0431 - accuracy: 0.9905 - val_loss: 5.8284 - val_accuracy: 0.5786\n",
      "Epoch 762/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0439 - accuracy: 0.9915 - val_loss: 5.7857 - val_accuracy: 0.5755\n",
      "Epoch 763/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0481 - accuracy: 0.9898 - val_loss: 5.8065 - val_accuracy: 0.5745\n",
      "Epoch 764/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0428 - accuracy: 0.9908 - val_loss: 5.8844 - val_accuracy: 0.5755\n",
      "Epoch 765/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0427 - accuracy: 0.9908 - val_loss: 5.9199 - val_accuracy: 0.5776\n",
      "Epoch 766/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0434 - accuracy: 0.9905 - val_loss: 5.9869 - val_accuracy: 0.5724\n",
      "Epoch 767/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0459 - accuracy: 0.9898 - val_loss: 5.8775 - val_accuracy: 0.5684\n",
      "Epoch 768/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0419 - accuracy: 0.9905 - val_loss: 5.8446 - val_accuracy: 0.5735\n",
      "Epoch 769/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0417 - accuracy: 0.9901 - val_loss: 5.9601 - val_accuracy: 0.5786\n",
      "Epoch 770/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0440 - accuracy: 0.9912 - val_loss: 5.9511 - val_accuracy: 0.5776\n",
      "Epoch 771/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0478 - accuracy: 0.9871 - val_loss: 6.1310 - val_accuracy: 0.5776\n",
      "Epoch 772/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0444 - accuracy: 0.9915 - val_loss: 5.9744 - val_accuracy: 0.5735\n",
      "Epoch 773/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0421 - accuracy: 0.9915 - val_loss: 5.8407 - val_accuracy: 0.5806\n",
      "Epoch 774/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0442 - accuracy: 0.9898 - val_loss: 5.8797 - val_accuracy: 0.5755\n",
      "Epoch 775/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0445 - accuracy: 0.9915 - val_loss: 5.7855 - val_accuracy: 0.5745\n",
      "Epoch 776/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0676 - accuracy: 0.9803 - val_loss: 6.4950 - val_accuracy: 0.5592\n",
      "Epoch 777/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2026 - accuracy: 0.9299 - val_loss: 6.6787 - val_accuracy: 0.5633\n",
      "Epoch 778/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1831 - accuracy: 0.9408 - val_loss: 5.8529 - val_accuracy: 0.5673\n",
      "Epoch 779/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1595 - accuracy: 0.9472 - val_loss: 5.4987 - val_accuracy: 0.5582\n",
      "Epoch 780/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1795 - accuracy: 0.9411 - val_loss: 6.1376 - val_accuracy: 0.5520\n",
      "Epoch 781/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1797 - accuracy: 0.9367 - val_loss: 5.6490 - val_accuracy: 0.5663\n",
      "Epoch 782/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1907 - accuracy: 0.9302 - val_loss: 6.4573 - val_accuracy: 0.5684\n",
      "Epoch 783/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1751 - accuracy: 0.9346 - val_loss: 5.4887 - val_accuracy: 0.5224\n",
      "Epoch 784/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2692 - accuracy: 0.9129 - val_loss: 6.4374 - val_accuracy: 0.5735\n",
      "Epoch 785/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2389 - accuracy: 0.9166 - val_loss: 5.6673 - val_accuracy: 0.5622\n",
      "Epoch 786/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1949 - accuracy: 0.9357 - val_loss: 5.7542 - val_accuracy: 0.5622\n",
      "Epoch 787/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1150 - accuracy: 0.9619 - val_loss: 5.6193 - val_accuracy: 0.5827\n",
      "Epoch 788/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0972 - accuracy: 0.9649 - val_loss: 5.6631 - val_accuracy: 0.5724\n",
      "Epoch 789/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0697 - accuracy: 0.9779 - val_loss: 5.7485 - val_accuracy: 0.5867\n",
      "Epoch 790/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0644 - accuracy: 0.9826 - val_loss: 5.5461 - val_accuracy: 0.5765\n",
      "Epoch 791/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0603 - accuracy: 0.9854 - val_loss: 5.7805 - val_accuracy: 0.5704\n",
      "Epoch 792/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0525 - accuracy: 0.9864 - val_loss: 5.7535 - val_accuracy: 0.5786\n",
      "Epoch 793/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0482 - accuracy: 0.9881 - val_loss: 5.8568 - val_accuracy: 0.5704\n",
      "Epoch 794/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0492 - accuracy: 0.9898 - val_loss: 5.8529 - val_accuracy: 0.5724\n",
      "Epoch 795/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0449 - accuracy: 0.9905 - val_loss: 5.7543 - val_accuracy: 0.5735\n",
      "Epoch 796/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0442 - accuracy: 0.9891 - val_loss: 5.8176 - val_accuracy: 0.5755\n",
      "Epoch 797/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0398 - accuracy: 0.9918 - val_loss: 5.8180 - val_accuracy: 0.5816\n",
      "Epoch 798/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 5.8472 - val_accuracy: 0.5704\n",
      "Epoch 799/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0384 - accuracy: 0.9915 - val_loss: 5.9369 - val_accuracy: 0.5673\n",
      "Epoch 800/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0371 - accuracy: 0.9929 - val_loss: 5.8211 - val_accuracy: 0.5735\n",
      "Epoch 801/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0373 - accuracy: 0.9918 - val_loss: 5.8684 - val_accuracy: 0.5786\n",
      "Epoch 802/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0356 - accuracy: 0.9939 - val_loss: 5.9276 - val_accuracy: 0.5735\n",
      "Epoch 803/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0346 - accuracy: 0.9929 - val_loss: 5.9145 - val_accuracy: 0.5765\n",
      "Epoch 804/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0346 - accuracy: 0.9925 - val_loss: 5.8918 - val_accuracy: 0.5765\n",
      "Epoch 805/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0341 - accuracy: 0.9925 - val_loss: 5.8804 - val_accuracy: 0.5765\n",
      "Epoch 806/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0334 - accuracy: 0.9939 - val_loss: 5.9958 - val_accuracy: 0.5724\n",
      "Epoch 807/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0344 - accuracy: 0.9935 - val_loss: 5.9196 - val_accuracy: 0.5765\n",
      "Epoch 808/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0339 - accuracy: 0.9935 - val_loss: 5.8814 - val_accuracy: 0.5755\n",
      "Epoch 809/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0334 - accuracy: 0.9939 - val_loss: 6.0035 - val_accuracy: 0.5724\n",
      "Epoch 810/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0343 - accuracy: 0.9929 - val_loss: 5.9822 - val_accuracy: 0.5735\n",
      "Epoch 811/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0338 - accuracy: 0.9946 - val_loss: 5.8709 - val_accuracy: 0.5765\n",
      "Epoch 812/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0376 - accuracy: 0.9915 - val_loss: 6.0812 - val_accuracy: 0.5714\n",
      "Epoch 813/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0343 - accuracy: 0.9932 - val_loss: 5.9783 - val_accuracy: 0.5724\n",
      "Epoch 814/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0333 - accuracy: 0.9942 - val_loss: 5.8698 - val_accuracy: 0.5745\n",
      "Epoch 815/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0352 - accuracy: 0.9929 - val_loss: 6.0939 - val_accuracy: 0.5755\n",
      "Epoch 816/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0332 - accuracy: 0.9946 - val_loss: 5.9261 - val_accuracy: 0.5765\n",
      "Epoch 817/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0344 - accuracy: 0.9929 - val_loss: 5.9942 - val_accuracy: 0.5724\n",
      "Epoch 818/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0329 - accuracy: 0.9942 - val_loss: 6.0840 - val_accuracy: 0.5735\n",
      "Epoch 819/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0342 - accuracy: 0.9935 - val_loss: 6.0326 - val_accuracy: 0.5755\n",
      "Epoch 820/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0323 - accuracy: 0.9942 - val_loss: 5.8986 - val_accuracy: 0.5796\n",
      "Epoch 821/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0323 - accuracy: 0.9942 - val_loss: 5.9993 - val_accuracy: 0.5786\n",
      "Epoch 822/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0325 - accuracy: 0.9929 - val_loss: 6.0621 - val_accuracy: 0.5765\n",
      "Epoch 823/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0323 - accuracy: 0.9942 - val_loss: 6.0452 - val_accuracy: 0.5755\n",
      "Epoch 824/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0322 - accuracy: 0.9949 - val_loss: 6.0132 - val_accuracy: 0.5735\n",
      "Epoch 825/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0312 - accuracy: 0.9956 - val_loss: 6.0202 - val_accuracy: 0.5786\n",
      "Epoch 826/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0312 - accuracy: 0.9939 - val_loss: 6.0743 - val_accuracy: 0.5776\n",
      "Epoch 827/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0306 - accuracy: 0.9946 - val_loss: 6.0919 - val_accuracy: 0.5745\n",
      "Epoch 828/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9946 - val_loss: 6.0343 - val_accuracy: 0.5765\n",
      "Epoch 829/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0294 - accuracy: 0.9959 - val_loss: 6.0721 - val_accuracy: 0.5776\n",
      "Epoch 830/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0298 - accuracy: 0.9956 - val_loss: 6.0473 - val_accuracy: 0.5786\n",
      "Epoch 831/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0297 - accuracy: 0.9949 - val_loss: 6.1928 - val_accuracy: 0.5765\n",
      "Epoch 832/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0315 - accuracy: 0.9946 - val_loss: 6.0334 - val_accuracy: 0.5786\n",
      "Epoch 833/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0304 - accuracy: 0.9946 - val_loss: 6.0009 - val_accuracy: 0.5776\n",
      "Epoch 834/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0311 - accuracy: 0.9946 - val_loss: 6.1482 - val_accuracy: 0.5816\n",
      "Epoch 835/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0307 - accuracy: 0.9952 - val_loss: 6.0000 - val_accuracy: 0.5796\n",
      "Epoch 836/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0302 - accuracy: 0.9946 - val_loss: 6.1444 - val_accuracy: 0.5735\n",
      "Epoch 837/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0308 - accuracy: 0.9946 - val_loss: 6.1172 - val_accuracy: 0.5735\n",
      "Epoch 838/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0299 - accuracy: 0.9952 - val_loss: 6.1103 - val_accuracy: 0.5765\n",
      "Epoch 839/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0348 - accuracy: 0.9939 - val_loss: 6.0426 - val_accuracy: 0.5714\n",
      "Epoch 840/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0374 - accuracy: 0.9932 - val_loss: 6.3193 - val_accuracy: 0.5694\n",
      "Epoch 841/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0365 - accuracy: 0.9929 - val_loss: 6.3350 - val_accuracy: 0.5806\n",
      "Epoch 842/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0380 - accuracy: 0.9922 - val_loss: 6.0149 - val_accuracy: 0.5837\n",
      "Epoch 843/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 0.9949 - val_loss: 6.0646 - val_accuracy: 0.5724\n",
      "Epoch 844/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9915 - val_loss: 6.2154 - val_accuracy: 0.5704\n",
      "Epoch 845/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0440 - accuracy: 0.9915 - val_loss: 6.4414 - val_accuracy: 0.5735\n",
      "Epoch 846/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0427 - accuracy: 0.9894 - val_loss: 6.3009 - val_accuracy: 0.5806\n",
      "Epoch 847/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0397 - accuracy: 0.9912 - val_loss: 6.1131 - val_accuracy: 0.5735\n",
      "Epoch 848/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0418 - accuracy: 0.9912 - val_loss: 5.9204 - val_accuracy: 0.5745\n",
      "Epoch 849/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0413 - accuracy: 0.9929 - val_loss: 6.1521 - val_accuracy: 0.5827\n",
      "Epoch 850/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0376 - accuracy: 0.9935 - val_loss: 6.2751 - val_accuracy: 0.5735\n",
      "Epoch 851/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0369 - accuracy: 0.9918 - val_loss: 6.3528 - val_accuracy: 0.5694\n",
      "Epoch 852/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0343 - accuracy: 0.9929 - val_loss: 6.1400 - val_accuracy: 0.5745\n",
      "Epoch 853/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0294 - accuracy: 0.9949 - val_loss: 6.1432 - val_accuracy: 0.5765\n",
      "Epoch 854/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0288 - accuracy: 0.9952 - val_loss: 6.2236 - val_accuracy: 0.5643\n",
      "Epoch 855/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0279 - accuracy: 0.9959 - val_loss: 6.2926 - val_accuracy: 0.5694\n",
      "Epoch 856/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9952 - val_loss: 6.1676 - val_accuracy: 0.5714\n",
      "Epoch 857/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 0.9963 - val_loss: 6.2229 - val_accuracy: 0.5735\n",
      "Epoch 858/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 0.9949 - val_loss: 6.4984 - val_accuracy: 0.5776\n",
      "Epoch 859/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0348 - accuracy: 0.9932 - val_loss: 6.1711 - val_accuracy: 0.5755\n",
      "Epoch 860/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0323 - accuracy: 0.9935 - val_loss: 6.1085 - val_accuracy: 0.5765\n",
      "Epoch 861/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0336 - accuracy: 0.9929 - val_loss: 6.2112 - val_accuracy: 0.5765\n",
      "Epoch 862/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0324 - accuracy: 0.9932 - val_loss: 6.3639 - val_accuracy: 0.5776\n",
      "Epoch 863/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 0.9952 - val_loss: 6.3200 - val_accuracy: 0.5796\n",
      "Epoch 864/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0316 - accuracy: 0.9956 - val_loss: 6.1306 - val_accuracy: 0.5806\n",
      "Epoch 865/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0301 - accuracy: 0.9939 - val_loss: 6.1896 - val_accuracy: 0.5796\n",
      "Epoch 866/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0295 - accuracy: 0.9956 - val_loss: 6.4245 - val_accuracy: 0.5724\n",
      "Epoch 867/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 6.2449 - val_accuracy: 0.5765\n",
      "Epoch 868/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0285 - accuracy: 0.9952 - val_loss: 6.3121 - val_accuracy: 0.5735\n",
      "Epoch 869/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0288 - accuracy: 0.9929 - val_loss: 6.3805 - val_accuracy: 0.5755\n",
      "Epoch 870/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0271 - accuracy: 0.9952 - val_loss: 6.2660 - val_accuracy: 0.5765\n",
      "Epoch 871/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9959 - val_loss: 6.3472 - val_accuracy: 0.5745\n",
      "Epoch 872/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0260 - accuracy: 0.9956 - val_loss: 6.3107 - val_accuracy: 0.5673\n",
      "Epoch 873/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0256 - accuracy: 0.9963 - val_loss: 6.2896 - val_accuracy: 0.5776\n",
      "Epoch 874/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9952 - val_loss: 6.4382 - val_accuracy: 0.5776\n",
      "Epoch 875/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0270 - accuracy: 0.9952 - val_loss: 6.3220 - val_accuracy: 0.5745\n",
      "Epoch 876/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0274 - accuracy: 0.9952 - val_loss: 6.1990 - val_accuracy: 0.5806\n",
      "Epoch 877/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 0.9922 - val_loss: 6.4488 - val_accuracy: 0.5735\n",
      "Epoch 878/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0288 - accuracy: 0.9956 - val_loss: 6.4583 - val_accuracy: 0.5745\n",
      "Epoch 879/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9952 - val_loss: 6.3163 - val_accuracy: 0.5796\n",
      "Epoch 880/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0277 - accuracy: 0.9952 - val_loss: 6.3063 - val_accuracy: 0.5724\n",
      "Epoch 881/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0278 - accuracy: 0.9952 - val_loss: 6.4921 - val_accuracy: 0.5724\n",
      "Epoch 882/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0283 - accuracy: 0.9956 - val_loss: 6.2708 - val_accuracy: 0.5765\n",
      "Epoch 883/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 0.9949 - val_loss: 6.4800 - val_accuracy: 0.5704\n",
      "Epoch 884/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0269 - accuracy: 0.9949 - val_loss: 6.3964 - val_accuracy: 0.5827\n",
      "Epoch 885/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0281 - accuracy: 0.9959 - val_loss: 6.3258 - val_accuracy: 0.5755\n",
      "Epoch 886/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0286 - accuracy: 0.9956 - val_loss: 6.3919 - val_accuracy: 0.5816\n",
      "Epoch 887/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0266 - accuracy: 0.9949 - val_loss: 6.3969 - val_accuracy: 0.5755\n",
      "Epoch 888/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0255 - accuracy: 0.9963 - val_loss: 6.4694 - val_accuracy: 0.5755\n",
      "Epoch 889/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0253 - accuracy: 0.9946 - val_loss: 6.4349 - val_accuracy: 0.5724\n",
      "Epoch 890/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9959 - val_loss: 6.3485 - val_accuracy: 0.5755\n",
      "Epoch 891/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0269 - accuracy: 0.9946 - val_loss: 6.4840 - val_accuracy: 0.5714\n",
      "Epoch 892/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0249 - accuracy: 0.9952 - val_loss: 6.5157 - val_accuracy: 0.5755\n",
      "Epoch 893/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0259 - accuracy: 0.9949 - val_loss: 6.4178 - val_accuracy: 0.5765\n",
      "Epoch 894/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0242 - accuracy: 0.9956 - val_loss: 6.3886 - val_accuracy: 0.5755\n",
      "Epoch 895/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0244 - accuracy: 0.9963 - val_loss: 6.4333 - val_accuracy: 0.5745\n",
      "Epoch 896/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0254 - accuracy: 0.9956 - val_loss: 6.4938 - val_accuracy: 0.5735\n",
      "Epoch 897/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0269 - accuracy: 0.9963 - val_loss: 6.3142 - val_accuracy: 0.5786\n",
      "Epoch 898/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0265 - accuracy: 0.9956 - val_loss: 6.5898 - val_accuracy: 0.5745\n",
      "Epoch 899/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0269 - accuracy: 0.9949 - val_loss: 6.4679 - val_accuracy: 0.5745\n",
      "Epoch 900/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.9966 - val_loss: 6.5395 - val_accuracy: 0.5786\n",
      "Epoch 901/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0254 - accuracy: 0.9949 - val_loss: 6.4935 - val_accuracy: 0.5755\n",
      "Epoch 902/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0238 - accuracy: 0.9969 - val_loss: 6.4924 - val_accuracy: 0.5796\n",
      "Epoch 903/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.9956 - val_loss: 6.4637 - val_accuracy: 0.5755\n",
      "Epoch 904/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0249 - accuracy: 0.9973 - val_loss: 6.5743 - val_accuracy: 0.5776\n",
      "Epoch 905/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0235 - accuracy: 0.9959 - val_loss: 6.5426 - val_accuracy: 0.5786\n",
      "Epoch 906/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0261 - accuracy: 0.9956 - val_loss: 6.4603 - val_accuracy: 0.5765\n",
      "Epoch 907/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 0.9949 - val_loss: 6.5682 - val_accuracy: 0.5796\n",
      "Epoch 908/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0275 - accuracy: 0.9963 - val_loss: 6.5611 - val_accuracy: 0.5765\n",
      "Epoch 909/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0282 - accuracy: 0.9949 - val_loss: 6.6056 - val_accuracy: 0.5827\n",
      "Epoch 910/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0344 - accuracy: 0.9946 - val_loss: 6.4304 - val_accuracy: 0.5796\n",
      "Epoch 911/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0286 - accuracy: 0.9952 - val_loss: 6.3919 - val_accuracy: 0.5816\n",
      "Epoch 912/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0307 - accuracy: 0.9956 - val_loss: 6.4156 - val_accuracy: 0.5735\n",
      "Epoch 913/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0351 - accuracy: 0.9929 - val_loss: 6.4619 - val_accuracy: 0.5786\n",
      "Epoch 914/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0299 - accuracy: 0.9942 - val_loss: 6.5171 - val_accuracy: 0.5786\n",
      "Epoch 915/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0313 - accuracy: 0.9942 - val_loss: 6.7623 - val_accuracy: 0.5847\n",
      "Epoch 916/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0278 - accuracy: 0.9956 - val_loss: 6.5870 - val_accuracy: 0.5735\n",
      "Epoch 917/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0252 - accuracy: 0.9949 - val_loss: 6.6595 - val_accuracy: 0.5694\n",
      "Epoch 918/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0228 - accuracy: 0.9969 - val_loss: 6.5679 - val_accuracy: 0.5735\n",
      "Epoch 919/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0246 - accuracy: 0.9956 - val_loss: 6.6340 - val_accuracy: 0.5714\n",
      "Epoch 920/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0266 - accuracy: 0.9959 - val_loss: 6.4881 - val_accuracy: 0.5765\n",
      "Epoch 921/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0269 - accuracy: 0.9969 - val_loss: 6.4449 - val_accuracy: 0.5765\n",
      "Epoch 922/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 6.5691 - val_accuracy: 0.5776\n",
      "Epoch 923/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0262 - accuracy: 0.9959 - val_loss: 6.8144 - val_accuracy: 0.5806\n",
      "Epoch 924/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0275 - accuracy: 0.9959 - val_loss: 6.5917 - val_accuracy: 0.5724\n",
      "Epoch 925/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0243 - accuracy: 0.9956 - val_loss: 6.4875 - val_accuracy: 0.5755\n",
      "Epoch 926/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0268 - accuracy: 0.9942 - val_loss: 6.5337 - val_accuracy: 0.5745\n",
      "Epoch 927/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0233 - accuracy: 0.9966 - val_loss: 6.7799 - val_accuracy: 0.5796\n",
      "Epoch 928/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0230 - accuracy: 0.9966 - val_loss: 6.7075 - val_accuracy: 0.5765\n",
      "Epoch 929/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0262 - accuracy: 0.9946 - val_loss: 6.6384 - val_accuracy: 0.5745\n",
      "Epoch 930/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0232 - accuracy: 0.9966 - val_loss: 6.4739 - val_accuracy: 0.5765\n",
      "Epoch 931/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0245 - accuracy: 0.9966 - val_loss: 6.5930 - val_accuracy: 0.5724\n",
      "Epoch 932/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0227 - accuracy: 0.9963 - val_loss: 6.7694 - val_accuracy: 0.5714\n",
      "Epoch 933/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0220 - accuracy: 0.9963 - val_loss: 6.6414 - val_accuracy: 0.5755\n",
      "Epoch 934/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0202 - accuracy: 0.9980 - val_loss: 6.6204 - val_accuracy: 0.5745\n",
      "Epoch 935/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0216 - accuracy: 0.9966 - val_loss: 6.6863 - val_accuracy: 0.5724\n",
      "Epoch 936/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0222 - accuracy: 0.9976 - val_loss: 6.8219 - val_accuracy: 0.5776\n",
      "Epoch 937/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0216 - accuracy: 0.9966 - val_loss: 6.6345 - val_accuracy: 0.5714\n",
      "Epoch 938/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0214 - accuracy: 0.9973 - val_loss: 6.7502 - val_accuracy: 0.5745\n",
      "Epoch 939/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0211 - accuracy: 0.9973 - val_loss: 6.7274 - val_accuracy: 0.5796\n",
      "Epoch 940/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0223 - accuracy: 0.9956 - val_loss: 6.7393 - val_accuracy: 0.5735\n",
      "Epoch 941/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 6.7526 - val_accuracy: 0.5765\n",
      "Epoch 942/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0220 - accuracy: 0.9966 - val_loss: 6.6568 - val_accuracy: 0.5745\n",
      "Epoch 943/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 0.9963 - val_loss: 6.7662 - val_accuracy: 0.5724\n",
      "Epoch 944/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0203 - accuracy: 0.9976 - val_loss: 6.6921 - val_accuracy: 0.5827\n",
      "Epoch 945/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0224 - accuracy: 0.9959 - val_loss: 6.7572 - val_accuracy: 0.5704\n",
      "Epoch 946/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0202 - accuracy: 0.9976 - val_loss: 6.8410 - val_accuracy: 0.5755\n",
      "Epoch 947/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9973 - val_loss: 6.7867 - val_accuracy: 0.5755\n",
      "Epoch 948/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 6.7217 - val_accuracy: 0.5745\n",
      "Epoch 949/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.9969 - val_loss: 6.8650 - val_accuracy: 0.5704\n",
      "Epoch 950/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0229 - accuracy: 0.9966 - val_loss: 6.9209 - val_accuracy: 0.5765\n",
      "Epoch 951/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0261 - accuracy: 0.9959 - val_loss: 6.8210 - val_accuracy: 0.5724\n",
      "Epoch 952/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0221 - accuracy: 0.9969 - val_loss: 6.7723 - val_accuracy: 0.5776\n",
      "Epoch 953/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0277 - accuracy: 0.9949 - val_loss: 6.6942 - val_accuracy: 0.5745\n",
      "Epoch 954/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0280 - accuracy: 0.9939 - val_loss: 6.7610 - val_accuracy: 0.5765\n",
      "Epoch 955/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0280 - accuracy: 0.9932 - val_loss: 6.8516 - val_accuracy: 0.5776\n",
      "Epoch 956/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0257 - accuracy: 0.9959 - val_loss: 6.9223 - val_accuracy: 0.5735\n",
      "Epoch 957/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0238 - accuracy: 0.9956 - val_loss: 6.8664 - val_accuracy: 0.5806\n",
      "Epoch 958/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0245 - accuracy: 0.9969 - val_loss: 6.8081 - val_accuracy: 0.5796\n",
      "Epoch 959/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0244 - accuracy: 0.9966 - val_loss: 6.8339 - val_accuracy: 0.5724\n",
      "Epoch 960/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0264 - accuracy: 0.9963 - val_loss: 6.8745 - val_accuracy: 0.5765\n",
      "Epoch 961/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 0.9959 - val_loss: 6.8063 - val_accuracy: 0.5765\n",
      "Epoch 962/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0255 - accuracy: 0.9966 - val_loss: 6.7690 - val_accuracy: 0.5714\n",
      "Epoch 963/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0254 - accuracy: 0.9956 - val_loss: 6.8074 - val_accuracy: 0.5735\n",
      "Epoch 964/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0259 - accuracy: 0.9963 - val_loss: 6.7656 - val_accuracy: 0.5776\n",
      "Epoch 965/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0260 - accuracy: 0.9966 - val_loss: 6.7296 - val_accuracy: 0.5755\n",
      "Epoch 966/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0250 - accuracy: 0.9959 - val_loss: 6.9863 - val_accuracy: 0.5827\n",
      "Epoch 967/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0264 - accuracy: 0.9946 - val_loss: 6.9527 - val_accuracy: 0.5755\n",
      "Epoch 968/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0217 - accuracy: 0.9973 - val_loss: 7.0597 - val_accuracy: 0.5786\n",
      "Epoch 969/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0228 - accuracy: 0.9973 - val_loss: 6.9699 - val_accuracy: 0.5745\n",
      "Epoch 970/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0215 - accuracy: 0.9969 - val_loss: 6.7497 - val_accuracy: 0.5796\n",
      "Epoch 971/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0238 - accuracy: 0.9956 - val_loss: 6.6691 - val_accuracy: 0.5765\n",
      "Epoch 972/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0262 - accuracy: 0.9952 - val_loss: 6.8383 - val_accuracy: 0.5735\n",
      "Epoch 973/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 0.9959 - val_loss: 6.9853 - val_accuracy: 0.5684\n",
      "Epoch 974/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0211 - accuracy: 0.9963 - val_loss: 7.0408 - val_accuracy: 0.5776\n",
      "Epoch 975/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0228 - accuracy: 0.9963 - val_loss: 6.8443 - val_accuracy: 0.5776\n",
      "Epoch 976/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0209 - accuracy: 0.9973 - val_loss: 6.8876 - val_accuracy: 0.5714\n",
      "Epoch 977/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 0.9976 - val_loss: 6.9884 - val_accuracy: 0.5765\n",
      "Epoch 978/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0184 - accuracy: 0.9980 - val_loss: 7.1414 - val_accuracy: 0.5786\n",
      "Epoch 979/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0228 - accuracy: 0.9966 - val_loss: 7.0444 - val_accuracy: 0.5745\n",
      "Epoch 980/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0236 - accuracy: 0.9952 - val_loss: 7.0737 - val_accuracy: 0.5745\n",
      "Epoch 981/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0259 - accuracy: 0.9959 - val_loss: 7.0869 - val_accuracy: 0.5796\n",
      "Epoch 982/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0232 - accuracy: 0.9966 - val_loss: 6.7950 - val_accuracy: 0.5714\n",
      "Epoch 983/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0218 - accuracy: 0.9966 - val_loss: 6.9603 - val_accuracy: 0.5663\n",
      "Epoch 984/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0198 - accuracy: 0.9976 - val_loss: 7.0777 - val_accuracy: 0.5724\n",
      "Epoch 985/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0200 - accuracy: 0.9973 - val_loss: 7.1266 - val_accuracy: 0.5745\n",
      "Epoch 986/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0241 - accuracy: 0.9959 - val_loss: 7.0615 - val_accuracy: 0.5684\n",
      "Epoch 987/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0227 - accuracy: 0.9956 - val_loss: 6.9729 - val_accuracy: 0.5796\n",
      "Epoch 988/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0218 - accuracy: 0.9956 - val_loss: 7.0985 - val_accuracy: 0.5704\n",
      "Epoch 989/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0388 - accuracy: 0.9922 - val_loss: 7.0324 - val_accuracy: 0.5776\n",
      "Epoch 990/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0421 - accuracy: 0.9922 - val_loss: 6.9646 - val_accuracy: 0.5796\n",
      "Epoch 991/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0400 - accuracy: 0.9918 - val_loss: 7.3150 - val_accuracy: 0.5827\n",
      "Epoch 992/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0413 - accuracy: 0.9888 - val_loss: 7.2579 - val_accuracy: 0.5786\n",
      "Epoch 993/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0364 - accuracy: 0.9918 - val_loss: 6.9081 - val_accuracy: 0.5806\n",
      "Epoch 994/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0322 - accuracy: 0.9918 - val_loss: 7.1432 - val_accuracy: 0.5673\n",
      "Epoch 995/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0348 - accuracy: 0.9915 - val_loss: 7.1677 - val_accuracy: 0.5776\n",
      "Epoch 996/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0355 - accuracy: 0.9898 - val_loss: 7.2165 - val_accuracy: 0.5663\n",
      "Epoch 997/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 6.9953 - val_accuracy: 0.5735\n",
      "Epoch 998/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0350 - accuracy: 0.9918 - val_loss: 6.9252 - val_accuracy: 0.5745\n",
      "Epoch 999/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0509 - accuracy: 0.9864 - val_loss: 6.9052 - val_accuracy: 0.5735\n",
      "Epoch 1000/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0557 - accuracy: 0.9837 - val_loss: 6.9934 - val_accuracy: 0.5776\n",
      "Epoch 1001/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0481 - accuracy: 0.9860 - val_loss: 7.2822 - val_accuracy: 0.5786\n",
      "Epoch 1002/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 6.9192 - val_accuracy: 0.5776\n",
      "Epoch 1003/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0414 - accuracy: 0.9901 - val_loss: 6.8902 - val_accuracy: 0.5745\n",
      "Epoch 1004/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0551 - accuracy: 0.9874 - val_loss: 7.3445 - val_accuracy: 0.5755\n",
      "Epoch 1005/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 6.8404 - val_accuracy: 0.5694\n",
      "Epoch 1006/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0727 - accuracy: 0.9803 - val_loss: 7.4680 - val_accuracy: 0.5765\n",
      "Epoch 1007/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0855 - accuracy: 0.9717 - val_loss: 6.9113 - val_accuracy: 0.5480\n",
      "Epoch 1008/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1453 - accuracy: 0.9592 - val_loss: 6.9954 - val_accuracy: 0.5684\n",
      "Epoch 1009/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1355 - accuracy: 0.9506 - val_loss: 7.3551 - val_accuracy: 0.5612\n",
      "Epoch 1010/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1773 - accuracy: 0.9462 - val_loss: 7.2784 - val_accuracy: 0.5847\n",
      "Epoch 1011/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1990 - accuracy: 0.9421 - val_loss: 6.6999 - val_accuracy: 0.5612\n",
      "Epoch 1012/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2652 - accuracy: 0.9238 - val_loss: 7.4130 - val_accuracy: 0.5714\n",
      "Epoch 1013/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.2176 - accuracy: 0.9353 - val_loss: 6.7861 - val_accuracy: 0.5714\n",
      "Epoch 1014/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2459 - accuracy: 0.9292 - val_loss: 7.3572 - val_accuracy: 0.5704\n",
      "Epoch 1015/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1933 - accuracy: 0.9411 - val_loss: 6.5750 - val_accuracy: 0.5653\n",
      "Epoch 1016/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1521 - accuracy: 0.9506 - val_loss: 6.6129 - val_accuracy: 0.5633\n",
      "Epoch 1017/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1235 - accuracy: 0.9575 - val_loss: 6.9470 - val_accuracy: 0.5745\n",
      "Epoch 1018/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0910 - accuracy: 0.9663 - val_loss: 6.7759 - val_accuracy: 0.5776\n",
      "Epoch 1019/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0596 - accuracy: 0.9806 - val_loss: 6.8416 - val_accuracy: 0.5786\n",
      "Epoch 1020/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0497 - accuracy: 0.9864 - val_loss: 6.6049 - val_accuracy: 0.5694\n",
      "Epoch 1021/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0355 - accuracy: 0.9915 - val_loss: 6.8010 - val_accuracy: 0.5786\n",
      "Epoch 1022/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0335 - accuracy: 0.9922 - val_loss: 6.8018 - val_accuracy: 0.5755\n",
      "Epoch 1023/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0275 - accuracy: 0.9942 - val_loss: 6.8610 - val_accuracy: 0.5704\n",
      "Epoch 1024/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0281 - accuracy: 0.9949 - val_loss: 6.6584 - val_accuracy: 0.5816\n",
      "Epoch 1025/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0287 - accuracy: 0.9939 - val_loss: 6.9821 - val_accuracy: 0.5786\n",
      "Epoch 1026/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0277 - accuracy: 0.9939 - val_loss: 6.7498 - val_accuracy: 0.5735\n",
      "Epoch 1027/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.9973 - val_loss: 6.8441 - val_accuracy: 0.5827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1028/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 6.8530 - val_accuracy: 0.5806\n",
      "Epoch 1029/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 6.9319 - val_accuracy: 0.5806\n",
      "Epoch 1030/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0189 - accuracy: 0.9976 - val_loss: 6.8470 - val_accuracy: 0.5735\n",
      "Epoch 1031/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0184 - accuracy: 0.9973 - val_loss: 6.8972 - val_accuracy: 0.5816\n",
      "Epoch 1032/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0186 - accuracy: 0.9973 - val_loss: 6.9193 - val_accuracy: 0.5755\n",
      "Epoch 1033/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0177 - accuracy: 0.9980 - val_loss: 6.8654 - val_accuracy: 0.5796\n",
      "Epoch 1034/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0172 - accuracy: 0.9983 - val_loss: 6.9346 - val_accuracy: 0.5776\n",
      "Epoch 1035/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0181 - accuracy: 0.9976 - val_loss: 6.8795 - val_accuracy: 0.5786\n",
      "Epoch 1036/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0169 - accuracy: 0.9980 - val_loss: 6.9668 - val_accuracy: 0.5796\n",
      "Epoch 1037/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0179 - accuracy: 0.9980 - val_loss: 6.8526 - val_accuracy: 0.5776\n",
      "Epoch 1038/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 7.0222 - val_accuracy: 0.5765\n",
      "Epoch 1039/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0167 - accuracy: 0.9983 - val_loss: 6.8834 - val_accuracy: 0.5786\n",
      "Epoch 1040/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0164 - accuracy: 0.9980 - val_loss: 7.0283 - val_accuracy: 0.5786\n",
      "Epoch 1041/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0162 - accuracy: 0.9980 - val_loss: 6.8759 - val_accuracy: 0.5816\n",
      "Epoch 1042/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0161 - accuracy: 0.9980 - val_loss: 7.0294 - val_accuracy: 0.5796\n",
      "Epoch 1043/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0159 - accuracy: 0.9983 - val_loss: 6.9485 - val_accuracy: 0.5796\n",
      "Epoch 1044/10000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0165 - accuracy: 0.9973 - val_loss: 6.9471 - val_accuracy: 0.5847\n",
      "Epoch 1045/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0158 - accuracy: 0.9980 - val_loss: 7.0534 - val_accuracy: 0.5776\n",
      "Epoch 1046/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0169 - accuracy: 0.9973 - val_loss: 7.0011 - val_accuracy: 0.5755\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=1000)\n",
    "modelpath = \"./model/wine_model{epoch:0003d}__{val_loss:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "history = model1.fit(X_train, y_train, epochs=10000, batch_size=500, validation_data=(X_valid, y_valid), callbacks=[early_stop, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c68cff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c2b8fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:22:42.017344: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.129142</td>\n",
       "      <td>0.132144</td>\n",
       "      <td>0.161516</td>\n",
       "      <td>0.150304</td>\n",
       "      <td>0.152587</td>\n",
       "      <td>0.137539</td>\n",
       "      <td>0.136768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137943</td>\n",
       "      <td>0.120878</td>\n",
       "      <td>0.175255</td>\n",
       "      <td>0.146764</td>\n",
       "      <td>0.142461</td>\n",
       "      <td>0.137926</td>\n",
       "      <td>0.138773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.122653</td>\n",
       "      <td>0.103567</td>\n",
       "      <td>0.202644</td>\n",
       "      <td>0.150664</td>\n",
       "      <td>0.130997</td>\n",
       "      <td>0.159185</td>\n",
       "      <td>0.130291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.124327</td>\n",
       "      <td>0.120584</td>\n",
       "      <td>0.175543</td>\n",
       "      <td>0.145644</td>\n",
       "      <td>0.141875</td>\n",
       "      <td>0.149688</td>\n",
       "      <td>0.142339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139661</td>\n",
       "      <td>0.111734</td>\n",
       "      <td>0.190197</td>\n",
       "      <td>0.146279</td>\n",
       "      <td>0.142211</td>\n",
       "      <td>0.135647</td>\n",
       "      <td>0.134270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.078802</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.327815</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.172843</td>\n",
       "      <td>0.135495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.111061</td>\n",
       "      <td>0.119064</td>\n",
       "      <td>0.173196</td>\n",
       "      <td>0.164721</td>\n",
       "      <td>0.161006</td>\n",
       "      <td>0.146776</td>\n",
       "      <td>0.124175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.128445</td>\n",
       "      <td>0.117547</td>\n",
       "      <td>0.165738</td>\n",
       "      <td>0.155297</td>\n",
       "      <td>0.146666</td>\n",
       "      <td>0.145050</td>\n",
       "      <td>0.141257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.102826</td>\n",
       "      <td>0.085074</td>\n",
       "      <td>0.220749</td>\n",
       "      <td>0.147508</td>\n",
       "      <td>0.131990</td>\n",
       "      <td>0.162144</td>\n",
       "      <td>0.149708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.114520</td>\n",
       "      <td>0.092554</td>\n",
       "      <td>0.233177</td>\n",
       "      <td>0.139498</td>\n",
       "      <td>0.120439</td>\n",
       "      <td>0.163107</td>\n",
       "      <td>0.136706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6\n",
       "0    0.129142  0.132144  0.161516  0.150304  0.152587  0.137539  0.136768\n",
       "1    0.137943  0.120878  0.175255  0.146764  0.142461  0.137926  0.138773\n",
       "2    0.122653  0.103567  0.202644  0.150664  0.130997  0.159185  0.130291\n",
       "3    0.124327  0.120584  0.175543  0.145644  0.141875  0.149688  0.142339\n",
       "4    0.139661  0.111734  0.190197  0.146279  0.142211  0.135647  0.134270\n",
       "..        ...       ...       ...       ...       ...       ...       ...\n",
       "975  0.078802  0.055556  0.327815  0.125396  0.104094  0.172843  0.135495\n",
       "976  0.111061  0.119064  0.173196  0.164721  0.161006  0.146776  0.124175\n",
       "977  0.128445  0.117547  0.165738  0.155297  0.146666  0.145050  0.141257\n",
       "978  0.102826  0.085074  0.220749  0.147508  0.131990  0.162144  0.149708\n",
       "979  0.114520  0.092554  0.233177  0.139498  0.120439  0.163107  0.136706\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_best_model = load_model(\"./model/wine_model001__1.8251.keras\")\n",
    "pred = wine_best_model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0fe50834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2\n",
      "1      2\n",
      "2      2\n",
      "3      2\n",
      "4      2\n",
      "      ..\n",
      "975    2\n",
      "976    2\n",
      "977    2\n",
      "978    2\n",
      "979    2\n",
      "Length: 980, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 행에서 확률이 가장 높은 클래스의 인덱스를 찾기\n",
    "predicted_classes = pred.idxmax(axis=1)\n",
    "\n",
    "# 결과 출력\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8def2315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1815    6\n",
      "4590    6\n",
      "452     7\n",
      "3761    7\n",
      "3899    5\n",
      "       ..\n",
      "1731    6\n",
      "4609    4\n",
      "460     5\n",
      "301     6\n",
      "2708    6\n",
      "Length: 980, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 행에서 확률이 가장 높은 클래스의 인덱스를 찾기\n",
    "y_classes = y_test.idxmax(axis=1)\n",
    "\n",
    "# 결과 출력\n",
    "print(y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "76dfb78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4590</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "1815  False  False  False   True  False  False  False\n",
       "4590  False  False  False   True  False  False  False\n",
       "452   False  False  False  False   True  False  False\n",
       "3761  False  False  False  False   True  False  False\n",
       "3899  False  False   True  False  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "1731  False  False  False   True  False  False  False\n",
       "4609  False   True  False  False  False  False  False\n",
       "460   False  False   True  False  False  False  False\n",
       "301   False  False  False   True  False  False  False\n",
       "2708  False  False  False   True  False  False  False\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d98ae229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           3       0.00      0.00      0.00       4.0\n",
      "           4       0.00      0.00      0.00      33.0\n",
      "           5       0.00      0.00      0.00     291.0\n",
      "           6       0.00      0.00      0.00     440.0\n",
      "           7       0.00      0.00      0.00     176.0\n",
      "           8       0.00      0.00      0.00      35.0\n",
      "           9       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00     980.0\n",
      "   macro avg       0.00      0.00      0.00     980.0\n",
      "weighted avg       0.00      0.00      0.00     980.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_classes, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "695a543c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ebb81276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9431fea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 4, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_labeled = le.fit_transform(y2)\n",
    "y_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70f8c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_scaled, y_labeled, test_size=0.4, stratify=y_labeled ,random_state=10)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_valid2, y_valid2, test_size=0.5, stratify=y_valid2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "980fb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95772742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        32\n",
      "           5       0.32      0.30      0.31       292\n",
      "           6       0.47      0.51      0.49       440\n",
      "           7       0.21      0.21      0.21       176\n",
      "           8       0.10      0.06      0.07        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.36       980\n",
      "   macro avg       0.16      0.16      0.16       980\n",
      "weighted avg       0.35      0.36      0.35       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=5, n_estimators=1000, n_jobs=-1, random_state=10)\n",
    "xgb.fit(X_train2, y_train2)\n",
    "xgb_pred = xgb.predict(X_valid2)\n",
    "print(classification_report(le.inverse_transform(y_test2), le.inverse_transform(xgb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa71f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb3f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
